{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from app.services.chat_service import ChatService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-formrecognizer\n",
      "  Downloading azure_ai_formrecognizer-3.3.3-py3-none-any.whl.metadata (64 kB)\n",
      "Requirement already satisfied: azure-core>=1.23.0 in d:\\senior_project\\esg-llm-finetune-and-graph-rag-mainesg (5)\\esg-llm-finetune-and-graph-rag-main\\.myvenv_py312\\lib\\site-packages (from azure-ai-formrecognizer) (1.32.0)\n",
      "Collecting msrest>=0.6.21 (from azure-ai-formrecognizer)\n",
      "  Downloading msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting azure-common>=1.1 (from azure-ai-formrecognizer)\n",
      "  Downloading azure_common-1.1.28-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in d:\\senior_project\\esg-llm-finetune-and-graph-rag-mainesg (5)\\esg-llm-finetune-and-graph-rag-main\\.myvenv_py312\\lib\\site-packages (from azure-ai-formrecognizer) (4.12.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in d:\\senior_project\\esg-llm-finetune-and-graph-rag-mainesg (5)\\esg-llm-finetune-and-graph-rag-main\\.myvenv_py312\\lib\\site-packages (from azure-core>=1.23.0->azure-ai-formrecognizer) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in d:\\senior_project\\esg-llm-finetune-and-graph-rag-mainesg (5)\\esg-llm-finetune-and-graph-rag-main\\.myvenv_py312\\lib\\site-packages (from azure-core>=1.23.0->azure-ai-formrecognizer) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\senior_project\\esg-llm-finetune-and-graph-rag-mainesg (5)\\esg-llm-finetune-and-graph-rag-main\\.myvenv_py312\\lib\\site-packages (from msrest>=0.6.21->azure-ai-formrecognizer) (2024.8.30)\n",
      "Requirement already satisfied: isodate>=0.6.0 in d:\\senior_project\\esg-llm-finetune-and-graph-rag-mainesg (5)\\esg-llm-finetune-and-graph-rag-main\\.myvenv_py312\\lib\\site-packages (from msrest>=0.6.21->azure-ai-formrecognizer) (0.7.2)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.21->azure-ai-formrecognizer)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\senior_project\\esg-llm-finetune-and-graph-rag-mainesg (5)\\esg-llm-finetune-and-graph-rag-main\\.myvenv_py312\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-formrecognizer) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\senior_project\\esg-llm-finetune-and-graph-rag-mainesg (5)\\esg-llm-finetune-and-graph-rag-main\\.myvenv_py312\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-formrecognizer) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\senior_project\\esg-llm-finetune-and-graph-rag-mainesg (5)\\esg-llm-finetune-and-graph-rag-main\\.myvenv_py312\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-formrecognizer) (2.4.0)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-formrecognizer)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Downloading azure_ai_formrecognizer-3.3.3-py3-none-any.whl (301 kB)\n",
      "Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\n",
      "Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: azure-common, oauthlib, requests-oauthlib, msrest, azure-ai-formrecognizer\n",
      "Successfully installed azure-ai-formrecognizer-3.3.3 azure-common-1.1.28 msrest-0.7.1 oauthlib-3.2.2 requests-oauthlib-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install azure-ai-formrecognizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ค่า Endpoint และ Key ถูกต้อง\n",
      "Endpoint: https://niceesgapp.cognitiveservices.azure.com/\n",
      "✅ พบไฟล์ PDF ที่: D:\\Senior_Project\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\pdf\\GRI 201_  Economic Performance 2016.pdf\n",
      "\n",
      "🚀 กำลังเชื่อมต่อกับ Azure และส่งเอกสารเพื่อวิเคราะห์...\n",
      "❌ เกิดข้อผิดพลาดที่ไม่คาดคิด: (404) Resource not found\n",
      "Code: 404\n",
      "Message: Resource not found\n"
     ]
    }
   ],
   "source": [
    "# === โค้ดฉบับสมบูรณ์ แก้ไขพาธ PDF แล้ว ===\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult\n",
    "\n",
    "# --- 1. ข้อมูลจาก Resource ใหม่ 'asdasd1qw' ---\n",
    "endpoint = \"https://niceesgapp.cognitiveservices.azure.com/\"\n",
    "key = \"DjdZme99xfTux0E6Qi4Gnu9N4HuzYYgc8WPAQOKybxEroO9QXqszJQQJ99BFACqBBLyXJ3w3AAALACOGCPAC\"\n",
    "\n",
    "\n",
    "print(\"✅ ค่า Endpoint และ Key ถูกต้อง\")\n",
    "print(f\"Endpoint: {endpoint}\")\n",
    "\n",
    "# --- 2. แก้ไขพาธ PDF เป็นที่อยู่เต็ม (Absolute Path) ---\n",
    "# ใช้ที่อยู่เต็มตามที่คุณส่งมา\n",
    "pdf_path = Path(r\"D:\\Senior_Project\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\pdf\\GRI 201_  Economic Performance 2016.pdf\")\n",
    "\n",
    "\n",
    "# --- 3. ตรวจสอบว่าไฟล์ PDF มีอยู่จริงหรือไม่ ---\n",
    "if not pdf_path.exists():\n",
    "    print(f\"❌ ข้อผิดพลาด: ไม่พบไฟล์ PDF ที่พาธนี้: {pdf_path.resolve()}\")\n",
    "    print(\"กรุณาตรวจสอบว่าพาธที่ให้มาถูกต้อง และชื่อไฟล์สะกดถูกต้องทุกตัวอักษร\")\n",
    "else:\n",
    "    print(f\"✅ พบไฟล์ PDF ที่: {pdf_path.resolve()}\")\n",
    "    # --- 4. เรียกใช้ Azure Document Intelligence API ---\n",
    "    try:\n",
    "        print(\"\\n🚀 กำลังเชื่อมต่อกับ Azure และส่งเอกสารเพื่อวิเคราะห์...\")\n",
    "        \n",
    "        document_intelligence_client = DocumentIntelligenceClient(\n",
    "            endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    "        )\n",
    "\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            poller = document_intelligence_client.begin_analyze_document(\n",
    "                \"prebuilt-document\", analyze_request=f, content_type=\"application/pdf\"\n",
    "            )\n",
    "        \n",
    "        result: AnalyzeResult = poller.result()\n",
    "        \n",
    "        print(\"\\n🎉🎉🎉 สำเร็จ! การเชื่อมต่อและการวิเคราะห์ทำงานถูกต้อง! 🎉🎉🎉\")\n",
    "        \n",
    "        # --- 5. แสดงผลลัพธ์ ---\n",
    "        if result.content:\n",
    "            print(\"\\n--- เนื้อหาทั้งหมดที่สกัดได้ ---\")\n",
    "            print(result.content)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ เกิดข้อผิดพลาดที่ไม่คาดคิด: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'Neo4jService' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m ChatService\u001b[38;5;241m.\u001b[39mcreate()\n",
      "File \u001b[1;32mc:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\app\\services\\chat_service.py:52\u001b[0m, in \u001b[0;36mChatService.create\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Use async with for the context manager\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m AsyncMongoDBSaver\u001b[38;5;241m.\u001b[39mfrom_conn_info(\n\u001b[0;32m     49\u001b[0m     url\u001b[38;5;241m=\u001b[39murl, db_name\u001b[38;5;241m=\u001b[39mdb_name\n\u001b[0;32m     50\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m memory:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Create an instance of ChatService\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     Neo4jService \u001b[38;5;241m=\u001b[39m \u001b[43mNeo4jService\u001b[49m()\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(memory, Neo4jService)\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'Neo4jService' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "chat = await ChatService.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gHYSUNDX1BST0ZJTEUAAQEAAAHIAAAAAAQwAABtbnRyUkdCIFhZWiAH4AABAAEAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAACRyWFlaAAABFAAAABRnWFlaAAABKAAAABRiWFlaAAABPAAAABR3dHB0AAABUAAAABRyVFJDAAABZAAAAChnVFJDAAABZAAAAChiVFJDAAABZAAAAChjcHJ0AAABjAAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAAgAAAAcAHMAUgBHAEJYWVogAAAAAAAAb6IAADj1AAADkFhZWiAAAAAAAABimQAAt4UAABjaWFlaIAAAAAAAACSgAAAPhAAAts9YWVogAAAAAAAA9tYAAQAAAADTLXBhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABtbHVjAAAAAAAAAAEAAAAMZW5VUwAAACAAAAAcAEcAbwBvAGcAbABlACAASQBuAGMALgAgADIAMAAxADb/2wBDAAMCAgMCAgMDAwMEAwMEBQgFBQQEBQoHBwYIDAoMDAsKCwsNDhIQDQ4RDgsLEBYQERMUFRUVDA8XGBYUGBIUFRT/2wBDAQMEBAUEBQkFBQkUDQsNFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBT/wAARCAGwAQIDASIAAhEBAxEB/8QAHQABAAIDAQEBAQAAAAAAAAAAAAUGBAcIAwIBCf/EAFcQAAEEAQIDAwYHCgsEBwkAAAEAAgMEBQYRBxIhExUxIkFRVpTTCBQWFzZV0SMyVGFxdHWBk9Q0QlJyc5WxsrO00iQ3YqEzNVNjgpHBGCUmQ0VHg5Kk/8QAGwEBAQADAQEBAAAAAAAAAAAAAAECAwQFBgf/xAA0EQEAAQICBggEBwEBAAAAAAAAAQIRA1ESFCExkdEEM0FSYnGSsRMVYaEFIiNTweHwgcL/2gAMAwEAAhEDEQA/AP6poiICIiAiIgIiICIiAiIgIiICIiAiKvXshdzd+bGYmZ1OKDybeTa1rjG4j/o4g4Fpk22JLgWt3HRxOwzoomuViLpuzcgpR9pYnjgj/lSvDR/5lYPyqwo/+sUPamfasGvw+0/FJ20+MhyNsgc1vIj4zMf/ABv3I/INh+JZx0vhif8Aqih7Mz7Fttgx2zPCOa7H58qsJ9cUPamfanyqwn1xQ9qZ9q/fkthfqih7Mz7E+S2F+qKHszPsT9H6/Y2Pz5VYT64oe1M+1PlVhPrih7Uz7V+/JbC/VFD2Zn2J8lsL9UUPZmfYn6P1+xsfnyqwn1xQ9qZ9qfKrCfXFD2pn2r9+S2F+qKHszPsT5LYX6ooezM+xP0fr9jYy6eSqZAE1bUFkDxMMgf8A2FZKgbWg9O23B7sLSjlBDmzwRCKVp9IezZw/UVjNnuaPliZcsy5LCSOEYuTkGeo4nye0IA54z0HP9807c3MCXMaFFfVztyn+P95Ja+5Z0RFzoIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIIzU+YGntN5TKFof8TqyWAw/wAYtaSB+sjZfmmsP3DgqlIuD5mN5p5R/wDNmcS6WQ/jc9znH8qxdeY6XLaKzlSuC6xLTlETQN938pLRt+UBSuOvxZXH1btcl0FmJs0ZI2Ja4Aj/AJFdG7Bi2e3hs/lexkoqvqjinovQ+Qjoaj1fgcBekiE7K2UycFaV0ZJAeGvcCWktcN/Ddp9Ch/8A2hOFmwPzlaQ2PTfv6r7xc6MjiXxax3DKbBVJ8Zlc7l85Ykr4/FYaBkticxxmSQjnexga1jSSS4fi3VF1Rx+zuJ4r6DwFHRGduYvP4axk54hXgjuRva6ENaRJYYGdmJCZWkb+Wzl5tnAOLGX09xl0zWg0rhaPFmOpa55JtNakrVreIm5D2U8UwkHI/fcdHg7b9HDcKvQ6N4p6Ym4Q6ryGJGu9S4PDXsVnK1e/DBMXWOxdHKJJS1knL2Ia87gknmAKDYmruPmO0Pqc43M6Y1PUxTbcFKTUxx7e645Zixse8nPz8pdI1peGFocdiRsV9ycdaEvEzMaGx2mtQ5nL4eWoy/PSrw/Fq8dhjXsldI+VvkgO6gDn8l3K1wBK0DxZ4Fa41hY152ugo9U6hu5ePIYXVF3LwNjp0I5IpGU4InO5opAGPjOzWscXlznrffDrSGYw/GHinqC/QNTG52TFvoSuljcZRFUEcgIa4lvK/cddt/EbjqgjPg78aM5xdo5yTM6VyOFNPKXq0VuVkDa5ZFZdEyHyZ5HmZrWjnO3JzB3KSNluJaH4XXcjwPk1XitbU6OA0pJncjk6WrbuXrRVJxasmaOEse8PZJtI8HcbeR0J3V4HwhOFh324l6PO3j/7+q+8QbAXjcpw5CnPVsxNmrzxuilieN2va4bEH8RBVVwHGPQOrMtDi8JrjTeZyc/N2VLH5avPNJytLncrGPJOzQSdh0AJVwVibbYFe0JcmsafbBYkM1ihPNRkkJJL+ykcxriT4ktDSfxlWFVjh+O1xN28N+S9kLVmPcbbxmUtYf1taD+QqzrdjxEYtVs1neIiLQgiIgIiICIiAiIgIiICIiAiIgIiICIiAqpXmZoOWSvZ2j09LI6SC2T5NNznFzopP5Me5JY770b8h5dmc1rX45oe0tcA5pGxB8CtlFejeJ2xKxLxfWrWw2R0UU24HK8tDtx5tj6F8920/wAFg/Zj7FBScPsbG9zsfPfwvMdyzHW3xRfqi3MY/U0L5OiJySflTnh+ITxe7WzQwp3V8Y5XLRmskNeKuCIomRA+PI0Ddeiq3yIn9ac9+3i90nyIn9ac9+3i90nw8Pv/AGlbRmtKLVeWxuVpcUNNYGPVOY7vyGLyNufmmh7TtIJKbY+X7n4bTyb9D/F8PPa/kRP60579vF7pPh4ff+0lozWaWGOdnLIxsjfHZw3C8e7an4LB+zH2Kv8AyIn9ac9+3i90nyIn9ac9+3i90nw8Pv8A2ktGaxR0q8Lw+OvEx48HNYAQq/lcm7Uz5sNiJi5h3jvZGInkrs8HRscPGYjcAD7z7538Vrw0BUn6X8ll8ozffsrN57Yz+VkfK1w/EQR+JWGnTr4+rFWqwR1q8TeWOGFgYxg9AA6AJE4eHtpm8/b+/sbIKlWGhVhrV42w14WNjjjYNmsaBsAPxABeyItEzfbLEREUBERAREQEREBERAREQEREBERAREQEREBERAREQEREGvtQlvz7aIG55u4c1sPNt22N38/5PN+sefYK19qHf59tEdW7dxZrxA3/AOmx3h59vydPDfzLYKAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIg17qED5+dDnmaD3Bm/JI6n7vjeo6f+vnC2EteahI+frQ3U83cGb2G3/f43zrYaAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIip9zV2Uv2Zm4GhUnqQvdE65esPjEj2nZwja1ji5oII5iR1B2BHVbcPCqxJ/KtrrgipHfmsPwHB+1Te7TvzWH4Dg/apvdrfqteccYLLuipHfmsPwHB+1Te7TvzWH4Dg/apvdpqteccYLOQuLPw8LeiPhItw0nDS1byOnnX8JBE3JhrrwsS1jFM0dgS0ObA0hoJ37QdTsF3Vip7dnF05r9VlK9JCx9irHL2rYZC0FzA/YcwB3HNsN9t9guc9VfB+m1bx707xVt0MMMxh4Oz+Ktmk7KxK3fsZnns9+aPc7fkZ/J67f781h+A4P2qb3aarXnHGCy7oqR35rD8BwftU3u0781h+A4P2qb3aarXnHGCy7oqR35rD8BwftU3u19DV2dxLHWcvjKT8fGC6aTHWJHyxNHi4RuYOcDqSAd9h0Dj0TVcTstP/AGCy6ovmKVk0bJI3tkjeA5r2ncOB8CCvpcaCIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAtdcPjvo/HHzkPJ/LzuWxVrrh79Dsb/Nd/fcvQ6P1VfnHtUvYsSIizQRFg4fOY/UNL45i7sGQqdrJD29aQPZzxvLHt3HTdrmuafQQUGciidQ6qxelW452UsmsMhdix1YiJ7+eeU7Rs8kHbcjxOwHnIUsoCIioLHyIBx9oEAgxO3B/IVkLHyH8As/0Tv7CrTvgZnD9xfoPTbnHcnG1iT/APiap9V/h79AdNfoyt/hNVgXDjdbV5z7rO8REWlBERAREQEREBERAREQEREBERAREQEREBa64e/Q7G/zXf33LYq11w9+h2N/mu/vuXodH6qvzj2qXsWJcvYLI5zGaX4z8Qps/ncvktL5rPDEYqXIzfEYmQxu5GPhDtpGgkkB24aGt5Q3bc9QqFwOjMNpmDKwY6i2CHK3Z8hcY97pBNPMd5XEPJ2Dv5I2HoAVmLo5/wCFGkuKNy/pLUD8tJNhcjAJsvPZ1fNkGXoJYCQ+Cv8AFI213h7mOaYntAAI677qkaexM+hPgZ66z+DzudqZj4xkoWSuzFl4rmPKSsDo2l+0byOrnNALiSSSSV0nozgRobh7mxldP4Pu641sjIgLc8kUDXnd7YonvLIgfQxrV4Wfg+aBtu1IX4Jwj1EHjJwR3rLIZy97ZHuEbZAxjnPY0lzA0nbqep3w0ZFF4n6UtcPX8NrFLVeqLNyzrKjXuS2s1Ycy0yYbSsfEHCPkPZAiMNDW8ztgNytfYU8XOL0eotUaevuo5Ovm7lKj2uqpa1WiK85jbDNjm1HxyeS0F3O8udz7gt3AHVGo9I4nVoxgy1T433ZeiyVT7o9nZ2I9+R/kkb7bnodwfOCqvkOAegsnq5+pp8A0ZiSxHblkhtTxRTTsILJZIWPEb3ggHmc0nceKs0zcaf1lqTVGD1hqbhXFmckzL6xydS7gsi21I6alRnDjkBFJvuwQCtOWAEcvbx7bdFDFnFDizqHiBZ09fsUpsDm7OExbm6smoxUuwDRG+WmKsrbHPuJHGV55g/YcoG66mtaZxd3UNDOz0opcvQgmrVbbh5cUcpYZGjzdezZ18enTxO9R1LwC0Fq7U0uoMpgGy5WfkFiWG1PA2zyfedtHG9rJdtgBzh3QAJNMi7Yj473TS7y7LvHsGfGfi+/Z9ryjn5d+vLzb7b+ZfeQ/gFn+id/YVkLHyH8As/0Tv7CttO+Bl8PfoDpr9GVv8JqsCr/D36A6a/Rlb/CarAuHH62rzn3Wd4iItKCIiAiIgIiICIiAiIgIiICIiAiIgIiIC11w9+h2N/mu/vuWxVQji8xpQyVKOJfmsb2j5IHVp445Yg5xcY3Nkc0EAk7ODvDYEAjc93R5iaaqL2mbTt2br5+bKN1k0ihO9s/6m5P2qn79O9s/6m5P2qn79dPw/FHqp5lk2ihO9s/6m5P2qn79O9s/6m5P2qn79Ph+KPVTzLJtFUrOt8hU1BQwkulMo3J3q89qvD29U88ULomyu5u22Gxni6E7nm6b7HaS72z/AKm5P2qn79Ph+KPVTzLJtFCd7Z/1NyftVP36d7Z/1NyftVP36fD8UeqnmWTax8h/ALP9E7+wqM72z/qbk/aqfv0fHqHPQPpNwk2FbM0xvt3LEL+zaehLWxPcXO2J23IG/irFFpvNUcY5lk9w9+gOmv0ZW/wmqwLHoUosbRrU4AWwV42xRgnchrQAP+QWQvLxKorrqqjtlJ3iIi1oIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgoGoG78cdEnboMHmRvt4fdsd59v8A1H5Dt0v619qFm/HbQ7tndMDmhvy9BvNjfPv+L/kfQtgoCIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiICIiDXuoSPn50MN/K7hzew5R/2+N8/m/J9i2Etf6gD/AJ9NEEGTk7izW4A8jftsdtufT47frWwEBERAREQEREBERAREQEREBERAREQEREBERAREQEREBERARQmW1xp7A2nVsjnMfRstALoZ7LGPaCNxu0ncb+ZYPzqaO9aMT7ZH9q3xgYtUXiibeUraVpRVb51NHetGJ9sj+1PnU0d60Yn2yP7VdWxu5PCV0ZyWlFVvnU0d60Yn2yP7U+dTR3rRifbI/tTVsbuTwk0Zya51bxf0Dj+O+l/jettOVn4/FZmnb7bLV2GtMZ6A7KTeQcj943+SRv5DvDYrdFG9WydKvcp2IrdSxG2aGxA8PjlY4btc1w6EEEEEdCCv5qcY/gz6c1d8MjH5GnmcedB6hnOYy1tlpnJXkaeaxE52/R0rurf6Q/ySv6C1+JmialeKCDUmGhhiaGMjjtRhrWgbAAA9AAmrY3cnhJozktqKrfOpo71oxPtkf2p86mjvWjE+2R/amrY3cnhJozktKKrfOpo71oxPtkf2p86mjvWjE+2R/amrY3cnhJozktKKvUeImlsnZjr1dRYuxPI4MZGy2wue4+DQN+pPoCsK1V0V4c2riY80tMbxERYIIiICIiAiIgIiICIiAiIgIiICIiAonVuTlwulczkITtNUpTTsJG/lNYXDp5+oUsq7xG/3e6o/Rdr/AAnLbgxFWJTE5wsb0dgMbDi8VXihb1LQ+SR3V8rz1c9xPUuJJJJJJJUgvGl/A4P6Nv8AYvZehVMzVMygiIsQREQEREBERAREQeVupBfrS17MMdivK0skilYHMe0+IIPQhffDu5Lc0tGJpZJ3VrVqm2SUlz3MhsSRNLiSS48rBuSST4nqV9LF4YfRix+lsn/np1MXqJ849pZdi2oiLzWIiIgIiICIiAiIgIiICIiAiIgIiICrvEb/AHe6o/Rdr/CcrEq7xG/3e6o/Rdr/AAnLfgdbR5x7rG+HhS/gcH9G3+xfOQv18VQs3bcrYKtaJ000rvBjGglzj+QAlfVL+Bwf0bf7Fj57DV9RYPI4m4HGpfrSVZg07Ese0tdsfTsSu2rfKNB6T+GVhtTai09WdSxUOJ1BcjpUJK2o6trIsfL0hNikzyog47A7OcWFwDgOu03o/wCEpJqHReodb5DTAxejMVVt2W3Y8nHYtudA8tMMtYNaYZHAEhpc7bpuRuFmcJNB8Q9BQ4HTmVk0nkdMYaH4rHlIY525KzBGwtgDoy0RxvGzOZ3O/flPQE7inZjg3qaTL6x1dqaDR+Lgn01kKFyDCxW5Isw57d2S3Yg0OPZhp6Rl8h5iA7wC0/mF40Jxm1HqLiPT0nqHRcWmJLmEkzkEoyotufEJYowwhsTQHgyeUN9h5Oxdudtjauz3yW0pms12Hxru2lNc7Dn5O07ONz+Xm2O2/LtvsdvQuSvg68RMfprVpfe31o+LC/Fn6lwt3I5ubHwRyRhlWSE043MD3v32YC7eMl42buN85/iNhOI2nsxpfFMzcOSzFGxRryZDTeTq12ySROa0ySvrhrG7nqSVaarxvFYpfCI1bkMjpCnFw2ja/V9B9/Cukz7AC1kbJHiztCey8iQEcnaE7gbDrtm1/hIy5TCYGHGaUmt61y2UvYhunpLzI2QT03OFp0lnlI7NnKCHBpLudoDdz0kcTwjzFDMcG7clmiY9G4exj8gGyP3lkkqwxNMXkdW80TieblOxHTzCr1+AmrMBfg1Hhr2GfqbHapzeXqV7r5fililkJCXQyvaznjkAEbt2tcA5m3lA7qfmE2/4SLKWm8ib2mLUOtaeai06NLw2WSOnuysEkIjn2DeydGe07RwGzWu3G42NLpcd8xoXXfFPM6+oS4WDGYzCNrYOPLttV+2nkssaYpHBjGc7uQOc5rdgwl3RoKlbnwedWZGje1NNmcRFxKm1LX1LEWMldjYzBB8WjqEkCR0ZhLgX7B27twOix8x8H3WvEG/rXLalyGBw+YykWHlxT8O6azHUtUJZpWmQSsZztcZGjp5i7oNgSnSEbqD4ULdZaB4j4WB2OxOpKmkshl6VzTOo4cnG0RxlpPbQhropWuewgEfja47FdFaPnktaSwk00jpZpKMD3yPcXOc4xtJJJ8SSteu0PrfXOhdY6e1jHpbEd8YmXG1pdOieUxvkjex8jzK1nTymEMA6bHdx36Xjh5j81iNEYWhqI0XZmpWbXsOxjnmu4s8lrm84DurQ0kEdCSOvisov2iwrF4YfRix+lsn/AJ6dZSxeGH0YsfpbJ/56dZYnUT5x7SyjdK2oiLzWIiIgIiICIiAiIgIiICIiAiIgIiICrvEb/d7qj9F2v8JysSidWYyTNaVzOOh6zW6U1dm528pzC0df1rbgzFOJTM5wsb0ZS/gcH9G3+xeyjsBk4Mpi4JInbPY0Mlid0fE8dHMc09Q4EEEEeZSK9CqJiqYlBERYgiIgIiICIiAiIgLF4YfRix+lsn/np193b1fG1ZLNueOtXjaXPlmeGtaB1JJPgvXh5SlpaXj7aGSu+zZtXBFKC17WzWJJWhwIBaeV43BG4PQ9Qpi9RPnHtLLsWVEReaxEREBERAREQEREBERAREQEREBERARFiZLLU8RHC+7ZjrNmnjrRGQ7c8r3BrGD0kkhBHZrR2nM1I+3lsJi70gG7p7lSOQgAedzh4AKpHQWmM/K1uF0ngIKTH1p+9ZcVXmguQO8t7YOUgklvIO0I5R2m45y1zRZmYq1qiNsucgdVovjsV5cC90U0FiN7uVrpzynmPZg/cw7kHavDu0LWObYgNhsOgW+MfFpi0VzEecrec1PocHtEY6q2CPSmIkaC53NPTjleSSXHdzgT4k7DwA2A2AAWR81ei/VHB/1dD/pVpRXWMbvzxldKc1W+avRfqjg/6uh/0p81ei/VHB/1dD/pVpRNYxu/PGTSnNVvmr0X6o4P+rof9KfNXov1Rwf9XQ/6VaUTWMbvzxk0pzVb5q9F+qOD/q6H/SnzV6L9UcH/AFdD/pVpRNYxu/PGTSnNU7HCXRNmCSF+ksKGSNLCY6MbHAEbdHNAIP4wQQoMcLtPYCzyu0hiMti5Za9eu2LFwusVWlvI98r3HeRvMGEuA5hzuJ3A3GyETWMbvzxk0pzVnBaM0cxtfJYbB4RoJEkNulUh8R4Oa5o83XqFZlX7uKmwRnyOFhfIGRTyPwlcRRx3JnuEheHOA5ZS7n68wa4yuL9zs5sxRv18jCZa8rZWhxY7lIJY4dHNcPM4HoQeoK1VV1VzeubpM33shERYIIiICIiAiIgIiICIiAiIgIiICIiCPzGZixUbGeTNenDxUpdo1slmRrS7kZufQOp8AOp2C8cXiJWWH5C/K+a/OyLmg7Uvr1XNYQRACBsCXyEvI53c2xPK1rW4+k5JctU78n+PxDIsZNXo5Ks2CWlEWN2iLAOZpJHM4PJcHOIPLsGtnkBERAREQEREBERAREQEREBQGbgfhJn5um14iibJNkaVOk2aa+0RgNLdtnmVnI3l2Lt28zeUksLJ9EHxFIJomSNDg14DhzNLTsfSD1H5CvtQGFrSYTNXcbHVmGMmBuwW5bna/dnvcZYWxu8pjW+S5uxLfujmjlDQDPoCIiAiIgIiICIiAiIgIiICIiAq/wAQdzoPUYacs1zsdYaHYH/rBu8bhvW6H7sPFnQ+Vt0KsC5Z+Hzxg4icGuHdfIaShxzsHk2y4zIXJI5hcoySMPZywyRysDTtzbEtOzg307IOpGMEbGtBJDRtuTuf/NfS1D8FbiNrXi1wgoat1xj8ZjL+Tmklp18XDLEz4oNmsc9skjzzOcJDvvsWlvTznbyAiIgIiICIiAiIgIiICIiAiIgrmtagbXx2XjpU7V3E3I7EclyfsWwROPZWHh/huIJJSA7yXENB26OFjWBn8TBnsFksZZrQXa12tJWlrWm80UrHtLSx487SCQR6CV5aXvzZTTWKuWHVXWZ6sUkxozdtBzloLuzf/Gbvvs7zhBKIiIPOzYZUryzyu5Yoml7negAblUOCfPamrQ5EZ2zg4LDBLDTowQOLGEbt53TRvJdt47BoHh123Ns1V9GMx+Zzf3Cq9pn6OYr80i/uBeh0eIiia7RM3tti/uy3RdjdzZz11zPs9H92TubOeuuZ9no/uym0W/T8MemORdCdzZz11zPs9H92TubOeuuZ9no/uym0TT8MemORdCdzZz11zPs9H92TubOeuuZ9no/uym0TT8MemORdCdzZz11zPs9H92TubOeuuZ9no/uym0TT8MemORdCdzZz11zPs9H92TubOeuuZ9no/uym0TT8MemORdCdzZz11zPs9H92UFrjhd85Glb+m9Saly2Uwt9gZYqvipsDwHBw8ptcOBBAO4IPRXhE+J4Y9NPJLq3jNKZLC42pj6OrstVpVIWQQQR1qIbHG1oa1o/2bwAACye5s5665n2ej+7KbRNPwx6Y5LdCdzZz11zPs9H92TubOeuuZ9no/uym0TT8MemORdCdzZz11zPs9H92TubOeuuZ9no/uym0TT8MemORdCdzZz11zPs9H92TubOeuuZ9no/uym0TT8MemORdCdzZz11zPs9H92TubOeuuZ9no/uym0TT8MemORdCdzZz11zPs9H92TubOeuuZ9no/uym0TT8MemORdEMyeW0tNXnu5WXNY2WaOvN8ahjZNCXuaxsjXRMa0gOcOZpb4EkOHLs69LXevPo2/8AOqv+YjWxFzdIiNGmu1pm8bNm63MndcREXCxFXOH0Ta+la1dkGMrMrTWK7YcRJz1o2xzvYGtPmcA0Bzf4ruYeZWNVzQrOyxN6Ps8TEG5S+QzDO3i8q1K7d/omPNvKP+0L0FjREQReqvoxmPzOb+4VXtM/RzFfmkX9wKw6q+jGY/M5v7hVe0z9HMV+aRf3AvRwepnz/hl2JJFj5CMTULMZsOqh0Tm9uwgOj3B8oE+BHj+pcI5LH4nRnB3idomtUxOXznyT72+VmAuusR5eo2cAy2GFx7Ofc8xO7g4bkO2Gyk1WYu9kXMfHHUeKzvFKqzHZKrfczh7qGZwrTNk5WSNr9m47HoHcrtvTsVWcBwj0lPqTgCyXDRzM1Hpy1LmmySPcMo5lSvKw2QXfduV7i4B+4HT0DaTVtHYSLjHTmApZ3McPNI5Fj7unqHEDU+JhpTSvc34pBFaMUDjvu6McrRykkEDYgjoo7J8P8DpnhfxZz+Mo/E8xpTWvYYK3HK/nxsLZqjhFBu77nGTNLuxuwPOdx4bNIdvouHfhGZGnkr/EXWmNhwGmsvpLJ1aUWTu2ZzmLNmMQO3gAlayGIteAByvDwHkgb7rcOn9A4DWfwoeJl7NUIsocZVwU1OKx5cUUvJO4Shn3peCxvK4jcAu2++O7SvNhuvAag7+dlB3ZkMb8RuyUt8hB2Qscoae2i6nmidzbB3Tcg9OillxrXwnDvS3C/iIM9pPF5qGhrzI0dP4Wdoax9uVsLIoWbkBoOwLj/Fa1x8ywNQ8OMdw601ws0Ljsxp2DAZrJXp9SXrMb5MVZyZga+GGVsM0R7M+W2OMvA+5R7h23VpDtlFqP4PGhnaIx+ooa+p8PncTPeaa9DAxPZTxkjYwJYow+eYt5jyvLOYAFx2A3Xh8KnKT4zhrRa67Pi8HbzmOp52/WkMT6+Okna2d3aN6sBBDS4eAcVlfZcbjRcu8U9OcPtGaQxmM0bPj8TpvKakxNfVfdF8hjcfI6QNMrmvPZMkeGMc/yeYF25Ko3FKriNL47jPp3QsrYNG18JiLU1fHTk16WSddIIiIJEbnRNjcQ0jqAfFYzVYdtouZs3wc067jDnuH+KqNw+B1PoSxJcggc4tdajtxMitEEneVvaE856kgbkqi39Vaz1zw51tr74vap6k0Ppt+mYS1pMkeS3acrai8CC1jIw1w9DuqaVh2mi5P4d8MqOJydfO6e1ro91V+DuTWcbpmtYimy1d8OzZZ+1uzcxZI6N3aFvNuSCfKWJpfglp7JfBQ0VPVuYvB5vKUMVPZv5uZzYspy8sjaNiTmDzC77wMaegDdgdtk0pyHXahdSawxWkn4hmTsGB+Wvx4ym1sbndpYe1zmt6Dp0Y87nYdPTsuUpM/pXiBo/RGh6Wi8Biu0ymWgMebvy2MRRlpuHbuiMb2fGQ4yjs27tAAd4cirtDG4LVPB3hgzUrsZqHFYfiTYwzb057Wu2iZLLWsD5HOPYu5YAA5x6CMbnYKaeQ7Tt6g+K6lx+H7syEwuQTT94RQc1SDsywckkm/kvdz+SNjvyu8NlLLmXibiq2muL2HyWhqFSLLDh7m48e+hG0iQwCsKrG7dC1pOzR+NVrRNLSenb3AfLaEvMt6s1BM0ZyWG46afI1XUpH25bYLjzOZMIzu4btd0G3grpbbDr9FxXwx0pi9McKvg+6vxtY1tS3s/Ux9vJCR5msVpW2GOgeSTvGA1uzPBvKNgF2osqZuK9rz6Nv8Azqr/AJiNbEWu9efRt/51V/zEa2IsekdVR5z/AOWXYIiLgYiruiYzFTygMOLg3ylxwGJdux28zjzSf98d93/8RKsSruiYTBUygNbHVebKW37Y1/M1+8rjzyeiU+Lx5nboLEiIgi9VfRjMfmc39wqvaZ+jmK/NIv7gVi1Q0v01lmgbk1JgAP5hVd0yQdN4kggg1IuoO/8AEC9HB6mfP+GXYkXsbIxzHtDmOGxa4bgj0KCwOgdMaWjux4XTmIxEd3+FMoUYoBY8fvw1o5vE+O/iVPIqxVjG8LtGYZhbj9I4Ki10UsJFbGwxgxy7dqzyWjyX8reYeDuUb77KVj0zh4ZcXLHiqLJMVE6DHvbWYDTjc0NcyI7fc2lrWghuw2aB5lJIlhDwaOwFW1DZhweNhsQWpr0U0dSNr47EoImmaQNxI8OcHOHV3Mdyd0m0dgLFHIUpcHjZaWRn+NXaz6kZjtTeSe0kaRs9/kM8p258lvoCmESwr+S4eaVzOWmyt/TOHvZOaA1pbtmhFJNJEW8pjc8tLi0gkcpO2x2UhjtPYrEWp7NDGU6VmxHFDNNXgZG+RkYIia4gAkMBIaD0AJ22UgiWFXzPCvRWooXw5XSGBycL7L7ro7mMgma6d4AfKQ5p8twABd4nYblflHhVorGYG3hKej8DUwtx4ks46DGQMrzuGwDnxhvK49B1I8wVpRLQKdkOHQr4qljdJZebQFGs57jX0/QpNjk5tvFksD2jbY/egeJ336bemntE5LHm5HnNXZPV9KzCYXUstTotiAPidoa8ZduNxs4kbHwVtRLCu4nhxpPA4q5jMZpfC47G3Rtap1MfDFDOPQ9jWgO8T4gr6p8PNK47T02AqaZw9bBTO55cXDQiZVkduDu6IN5SdwD1HmHoVgRLQMM4ag7Ltypo1jlGQGq28YW9uIS4OMYftzchc1p5d9twD5l61qNam2VtevFA2WR0sgjYGh73Hdzjt4knxPnXuior2E4daU0zNcmw+mMNipboLbUlHHxQunB8Q8taOYH8e697eidO5DTkWn7WBxlnAwsbFHi5qcb6rGNGzWiIt5QAPAAdFNIpYV25w50nkcFUwlvS+GtYam4PrY6bHxPrwOG+xZGW8rT1PUDzle02hNNWMVfxkunsVJjchL21ym+lEYbMmzRzyM5dnu2YwbkE+S30BTiJaBFUdJ4PGS0JaeGx9STHwOq03wVWMNaFxaXRxkDyGEtbu0bA8o9Cx8NoPTOnctbymJ07icZk7m/xm7ToxQzT7nc872tBd169Sp1EEPDo7AV8djcfFg8bFQxkrZ6NVlSMRVJG78r4mgbMcOZ2xaARufSphEQV7Xn0bf8AnVX/ADEa2Itea7HNpxwHibVQAek/GI9gthrDpHVUec/wy7BERcDEVc0RD2FPKf7Nj6vNlbj9sbJztfvM7y3nzSnxePM7cKxqu6Gr9hjL/wDslCnz5S8/lx0naMfvZk8tx80jvF48zy4eZBYkREH45oe0tcAWkbEHzqmP0dmsX9wwmVpx45vSKvkKj5nwjzNa9sjd2jzAgkDzlXRFuw8WrCvo81ibKT3BrD60wfsE3vk7g1h9aYP2Cb3yuyLdrWJlHCFupPcGsPrTB+wTe+TuDWH1pg/YJvfK7ImtYmUcILqT3BrD60wfsE3vk7g1h9aYP2Cb3yuyJrWJlHCC6k9waw+tMH7BN75O4NYfWmD9gm98rsia1iZRwgupPcGsPrTB+wTe+TuDWH1pg/YJvfK7ImtYmUcILqT3BrD60wfsE3vlX+IN3V+g9Cah1I61hbzcRQnvGsylMwy9mwv5Ae1O2+22+xW1lQeP7HP4FcRA1naOGncg5rOnlEVpCB1BHXbzg/kKa1iZRwguyO4NYfWmD9gm98ncGsPrTB+wTe+VygnZZgjmjPNHI0PafSCNwvRNaxMo4QXUnuDWH1pg/YJvfJ3BrD60wfsE3vldkTWsTKOEF1J7g1h9aYP2Cb3ydwaw+tMH7BN75XZE1rEyjhBdSe4NYfWmD9gm98ncGsPrTB+wTe+V2RNaxMo4QXUnuDWH1pg/YJvfJ3BrD60wfsE3vldkTWsTKOEF1J7g1h9aYP2Cb3ydwaw+tMH7BN75XZE1rEyjhBdU8fpLI2LcE+cyNe3FXeJYqtKu6GMyAgtc8ue4u5SNwOgB2J3IBFsRFoxMSrEm9SXuIiLUgq5oGs6tp081ShSdLeu2DHjZOeF3aWpZOfm87383O/8A43OVgllZBE+SRzWRsaXOc47AAeJJPgoLQFF2O0ThIH06NCb4pG+WtjJDJWjkcOZ4ieerm8xOzj4jr50FgREQEREBERAREQEREBERAREQFg5zExZ7C5DGTkiC7XkrSEePK9paf+RWciCl8GMvNmuFmmpbTg7IV6jaN4Ak8tuuTBYb169JYpB+pXRa9jf82utrRn+56X1LbY+Oc/eUsk/ZhY877NZYIj5D0HbczSS6ZgWwkBERAREQEREBERAREQEREBERBX9dyE6Yt02DHSz5ACjFBlJuygndJ5JYSOp3aXeS3qdth6VOV68VSvFBBG2KGJoYyNg2DWgbAAegBV6vLBqzUDbMRoXsViJZI2OfWc+aPIN3je6OR3kgMY6SMlm55nvaS0sc02VAREQEREBERAREQEREBERAREQEREGPkMfVy1CzRvVoblKzE6GetYjEkcsbgQ5jmno5pBIIPQgqis784Xsc3ku6q0kz7ws57OUxzNj0I6vtxjoBtvMPRMTu3YSII7AahxmqsVDksRfgyVCbfksV3h7SQdiOngQQQQeoIIOxUiqbnuHENjJz5vT11+mNRSkOluVWc8FsjYD41X3DJugA5jtI0dGyN3KxcfxImwtyDF63pR6dvyvbDXyMchkxl15OzRHOQOzkcdtopQ1xJ2YZNuZBfEUcdRYoZ/uLvOn338W+Od2/GGfGew5iztez35uTmBbzbbbjbfdSKAiIgIiICIiAiiMrqzD4PNYTEXshDWyebmlgx1Rx3ksujidLJygeZrGOJceg6DfdzQfPJanjisW6GMh73zFYQOlowytYYmyv5Wvkc7o0ABziOri1h5WuOwITaq4yMmuqQbjHyQ6eu1ZActFLJXsl3PyAQtLAeUtEjhNuOhjdHzh3M3Kj00+9ZE+csR5WSvffcosZCYYqzduWNpbzO7RzRued2/lOLmhg5WtnkH4BsF+oiAiIgIiICIiAiIgIiICIiAiIgIiICIiAvC7Sr5KpNVtwRWqszSyWCZgex7T4hzT0IPoK91T+JWuTo3FwsqiOTLXXFlWOTq1obtzyOA8WtBHTzlzR033G7Cwq8euMOiLzI/m3a4Nce+DvHOnxIlx+MGVbbE0eOp5hkrXVd+T4tHG+Qy9g2PaIDrytDRv0C/oFB8IHEyV4ZHYLNskewOfH2MXkOI6t3Mg328Nx0WqiHSTzWJpX2LUzuaaxMeaSQ+lx/sHgB0AAGy/V9jhfgvR6af1JmZ4QXhtf5/sR9R5z9jD71Pn+xH1HnP2MPvVqhFv+T9EyniaX0bX+f7EfUec/Yw+9T5/sR9R5z9jD71aoRPk/RMp4ml9G1/n+xH1HnP2MPvV9M4+4Zx8rDZuMekwRH+yQlamRPk/RMp4ml9HNfHnQPGj4S/H+fN6ehjxdbETdlp9smVjpzxRRO5mzxtLhJzuPllzRu3cDfoF/R7Q9bIVNGYKLL1KtDLtoV23a1JxdBFOImiRjHOJJaHAgEknYDqVzlNAydoD277EOafAtI8CD4gjzEdQtxcKNezZvtMJlJe1yNeLtYZz99YhBAJd/xtJAPp5mn07eJ0/8K1ej4uDN6Y3xO+DfubHREXzgIiICIiAiIgIiICIiAiIgIiICIiAiIgIiIC0DxXuOu8R7jHE8tOpBAxu/Qc3M9x29J5mj/wAIW/lo3jLiH47WlfJcv+zZKs2Hm9E0RcSP1scCB/wOXu/g00x0q09sTb/eV17JUtF4X7L6dKeeOtLckiYXtrwcvaSkD71vMWt3PgNyB+MKpniBlR/9v9Tf/tQ/el9xVXFO/wBpa1zWg8f8ITOZl8GWx2JF3Bz2xFFjocRkH2nwdpydqLIj7Dfby+Tw2G3Putm19d5OaeON2hNSQte4NMkjqPKwE+J2sk7D8QJUTpXhfmdFWoqWI1a+DSkVp1iPESY9kksbXPL3QtnLuke5O3k8wB25lyYs4mJMfCvbt2cN9vrn5KreV4tatoYzVufZVwxwem8xJQmruZL8ZswsewOc13NyscGvHiHBxB6NXvr3WOptTRa7xunIMVFh8HTkrXrOSEjpLEzoO0eyIMIDOVrm+U7fqfDbqpvJcHu8NF620/3v2fylyE174x8W3+LdpyeRy8/l7cnjuN9/BeeoeEmTuZjUdrBaoODp6hi5cjSkoNstdJ2fZdpG4ubyEsAB8Qdt1pqox7Wm8xP1j6/1/rix8LP92OkP0PT/AMBitCoeKy+Q0RiMdp6HSeezUeLqQ025CqKbIrHJG1vO1r7IcN9vAj/z8VlHX+UAH/wBqY7jzOodP/6l10YkU0xTN7x9JRclnaauuxus9OWmHZwvxwHrtu2XeIg+n7/f8oHoUFg8nNl6DbNjGXMRIXEGreMRkG3nPZve3Y/zlatBYd+e15h4Wt5oabzfnd/JawEM/WZCzp5w13oKdIqpjArqq3Wn2ZU73RaIi/MFEREBERAREQEREBERAREQEREBERAREQEREBRWptN0tWYebHXmu7KTq2SM7SRPH3r2HzOB/KD1BBBIMqiypqqoqiqmbTA5t1LpPMaNlkGSrPnps3LcnVjLoXj0uAJMZ9Id09DnbKvjNY8+F6sdun/TN+1dZLCnwuPtPL5qFaZ5/jSQtcf+YX1GF+OzFNsWi85xNvtY2OW++KH4dW/bN+1O+KH4dW/bN+1dQfJzE/VdL2dn2J8nMT9V0vZ2fYt/z7D/AG54/wBFocv98UPw6t+2b9qd8UPw6t+2b9q6g+TmJ+q6Xs7PsT5OYn6rpezs+xPn2H+3PH+i0OX++KH4dW/bN+1fhzOPAJN6sAPP2zftXUPycxP1XS9nZ9i+o8DjInhzMdUY4eDmwNB/sT59h/tzx/otDnDBYnJarmEWFpPu7ktNl27K0f43SbbfqbzO/Et9aG0TW0Vi3Qsk+NXZyJLVtzeUyuA2AA3PKweZu523JJJLibGAAAANgPMv1eN038SxOmRoW0acucnkIiLxwREQEREH/9k=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat.graph\n",
    "display(Image(chat.graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-30 23:17:35.452579\n"
     ]
    }
   ],
   "source": [
    "import datetime as datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'igraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01migraph\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(igraph\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m      3\u001b[0m exit()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'igraph'"
     ]
    }
   ],
   "source": [
    "import igraph\n",
    "print(igraph.__version__)\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading files...\n",
      "Time taken to upload files:  125.60201597213745\n",
      "Status Code: 200\n",
      "Response Headers: {'date': 'Sun, 08 Jun 2025 11:55:45 GMT', 'server': 'uvicorn', 'content-length': '260', 'content-type': 'application/json'}\n",
      "Response Text (content): {\"status\":\"Success\",\"message\":\"Successfully processed 1 files for Knowledge Graph ingestion. Question AI baseline generation has been triggered in the background.\",\"original_filenames\":[\"GRI 201_  Economic Performance 2016.pdf\"],\"neo4j_service_response\":\"N/A\"}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "url = \"http://127.0.0.1:5050/api/v1/graph/uploadfile\" # สมมติว่าคุณใช้ port 5050 ตามที่ app/main.py กำหนด\n",
    "\n",
    "files = [\n",
    "    ('files', ('GRI 201_  Economic Performance 2016.pdf', open('./pdf/GRI 201_  Economic Performance 2016.pdf', 'rb'), 'application/pdf'))\n",
    "]\n",
    "print(\"Uploading files...\")\n",
    "start = time.time()\n",
    "response = requests.post(url, files=files) # ลองเอา timeout ออกไปก่อน หรือตั้งให้นานมากๆ\n",
    "end = time.time()\n",
    "print(\"Time taken to upload files: \", end-start)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(\"Response Headers:\", response.headers)\n",
    "print(\"Response Text (content):\", response.text) # ดูว่าเนื้อหาเป็นอะไร\n",
    "\n",
    "# หลังจากดู response.text แล้ว ถ้าคิดว่าเป็น JSON ค่อยลองเรียก .json()\n",
    "# try:\n",
    "#     print(\"JSON Response:\", response.json())\n",
    "# except requests.exceptions.JSONDecodeError as e:\n",
    "#     print(\"Failed to decode JSON:\", e)\n",
    "#     print(\"As mentioned, the response text was:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading batch 1...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "url = \"http://127.0.0.1:5050/api/v1/graph/uploadfile/\"\n",
    "pdf_folder = 'pdf'  # Folder containing PDF files\n",
    "batch_size = 1  # Number of files to upload in each batch\n",
    "\n",
    "# Get all PDF files from the folder\n",
    "pdf_files = [f for f in os.listdir(pdf_folder) if f.endswith('.pdf')]\n",
    "pdf_files = pdf_files[:1]\n",
    "\n",
    "# Process files in batches\n",
    "for i in range(0, len(pdf_files), batch_size):\n",
    "    # Prepare batch of files\n",
    "    files = []\n",
    "    for pdf_file in pdf_files[i:i + batch_size]:\n",
    "        file_path = os.path.join(pdf_folder, pdf_file)\n",
    "        files.append(('files', (pdf_file, open(file_path, 'rb'), 'application/pdf')))\n",
    "    \n",
    "    # Upload batch\n",
    "    print(f\"Uploading batch {i // batch_size + 1}...\")\n",
    "    start = time.time()\n",
    "    response = requests.post(url, files=files)\n",
    "    end = time.time()\n",
    "    print(\"Time taken to upload batch: \", end - start)\n",
    "\n",
    "    # Print response\n",
    "    if response.status_code == 200:\n",
    "        print(\"Batch upload successful:\", response.json())\n",
    "    else:\n",
    "        print(\"Batch upload failed with status code:\", response.status_code, response.text)\n",
    "\n",
    "    # Close file objects to free resources\n",
    "    for file_tuple in files:\n",
    "        file_tuple[1][1].close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DocumentIntelligenceClient with endpoint: https://mayesgprojec...\n",
      "Sending request to analyze document from URL: https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf using model: prebuilt-layout\n",
      "\n",
      "An HTTP error occurred: 404\n",
      "Error Code: 404\n",
      "Error Message: Resource not found\n",
      "This is a 'Resource not found' error.\n",
      "Please double-check:\n",
      "1. Endpoint: 'https://mayesgproject.cognitiveservices.azure.com/' is correct and the service exists.\n",
      "2. Model ID: 'prebuilt-layout' is valid for your endpoint and resource.\n",
      "3. Document URL/Path: 'https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf' (or path) is accessible.\n",
      "4. API Key: Ensure it's correct and has permissions for the specified endpoint/resource.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest\n",
    "\n",
    "# --- กรุณาใส่ค่าเหล่านี้ ---\n",
    "# ดูได้จาก Azure Portal -> Cognitive Services -> [ชื่อ Resource ของคุณ] -> Keys and Endpoint\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = \"https://mayesgproject.cognitiveservices.azure.com/\"\n",
    "AZURE_DOCUMENT_INTELLIGENCE_KEY = \"FsyV77ZBSIK9UxlOmECm6Q9TBb0zrugt9ZRdH2ji1d6moQDrN2PqJQQJ99BFACqBBLyXJ3w3AAALACOGg4WL\"\n",
    "\n",
    "# Model ID ที่ต้องการทดสอบ\n",
    "# สำหรับโมเดลพื้นฐาน ลองใช้:\n",
    "# \"prebuilt-read\" -> สำหรับ OCR\n",
    "# \"prebuilt-layout\" -> สำหรับโครงสร้างเอกสาร, ตาราง, ข้อความ\n",
    "# \"prebuilt-document\" -> สำหรับการดึงข้อมูลทั่วไป (key-value pairs)\n",
    "# หากเป็น custom model ให้ใส่ ID ของ custom model ของคุณ\n",
    "MODEL_ID = \"prebuilt-layout\"\n",
    "\n",
    "# URL ของเอกสาร PDF ที่ต้องการทดสอบ (ต้องเป็น URL ที่เข้าถึงได้แบบสาธารณะ)\n",
    "# ตัวอย่าง: คุณสามารถอัปโหลด PDF ของคุณไปยัง Azure Blob Storage แล้วใช้ URL นั้น\n",
    "# หรือหา PDF ตัวอย่างออนไลน์ เช่น:\n",
    "DOCUMENT_URL = \"https://www.w3.org/WAI/ER/tests/xhtml/testfiles/resources/pdf/dummy.pdf\"\n",
    "# หรือถ้าต้องการทดสอบไฟล์ในเครื่อง (ยกตัวอย่าง)\n",
    "# DOCUMENT_PATH = \"path/to/your/local/document.pdf\"\n",
    "\n",
    "def analyze_document_from_url():\n",
    "    print(f\"Initializing DocumentIntelligenceClient with endpoint: {AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT[:20]}...\")\n",
    "    try:\n",
    "        document_intelligence_client = DocumentIntelligenceClient(\n",
    "            endpoint=AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT,\n",
    "            credential=AzureKeyCredential(AZURE_DOCUMENT_INTELLIGENCE_KEY)\n",
    "        )\n",
    "\n",
    "        print(f\"Sending request to analyze document from URL: {DOCUMENT_URL} using model: {MODEL_ID}\")\n",
    "\n",
    "        # สร้าง request object\n",
    "        # สำหรับการวิเคราะห์จาก URL\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            model_id=MODEL_ID,\n",
    "            analyze_request=AnalyzeDocumentRequest(url_source=DOCUMENT_URL)\n",
    "        )\n",
    "        \n",
    "        # # หากต้องการวิเคราะห์จากไฟล์ในเครื่อง ให้ comment บรรทัดข้างบน และ uncomment ส่วนนี้:\n",
    "        # with open(DOCUMENT_PATH, \"rb\") as f:\n",
    "        #     poller = document_intelligence_client.begin_analyze_document(\n",
    "        #         model_id=MODEL_ID,\n",
    "        #         analyze_request=f # ส่ง binary content โดยตรง\n",
    "        #         # content_type=\"application/octet-stream\" # Optional, SDK มักจะ detect ได้\n",
    "        #     )\n",
    "\n",
    "        result = poller.result() # รอให้การวิเคราะห์เสร็จสิ้น\n",
    "\n",
    "        print(\"\\n---- Analysis Results ----\")\n",
    "        if result.pages:\n",
    "            print(f\"Document has {len(result.pages)} page(s).\")\n",
    "            for i, page in enumerate(result.pages):\n",
    "                print(f\"\\n--- Page #{i + 1} ---\")\n",
    "                print(f\"  Dimensions: {page.width}x{page.height} {page.unit}\")\n",
    "                if page.lines:\n",
    "                    print(f\"  Found {len(page.lines)} lines.\")\n",
    "                    # พิมพ์ 3 บรรทัดแรกเป็นตัวอย่าง\n",
    "                    for line_idx, line in enumerate(page.lines[:3]):\n",
    "                        print(f\"    Line {line_idx + 1}: '{line.content}'\")\n",
    "                if page.tables:\n",
    "                    print(f\"  Found {len(page.tables)} table(s) on page {i+1}.\")\n",
    "                    for table_idx, table in enumerate(page.tables):\n",
    "                        print(f\"    Table {table_idx + 1} has {table.row_count} rows and {table.column_count} columns.\")\n",
    "\n",
    "\n",
    "        if result.styles and any(style.is_handwritten for style in result.styles):\n",
    "            print(\"Detected handwritten content in the document.\")\n",
    "        else:\n",
    "            print(\"No handwritten content detected (or model does not support this).\")\n",
    "\n",
    "        print(\"\\n---- Raw Result (first 500 chars) ----\")\n",
    "        print(str(result)[:500] + \"...\") # แสดงผลลัพธ์บางส่วน\n",
    "\n",
    "        print(\"\\nAnalysis completed successfully!\")\n",
    "\n",
    "    except HttpResponseError as e:\n",
    "        print(f\"\\nAn HTTP error occurred: {e.status_code}\")\n",
    "        print(f\"Error Code: {e.error.code if e.error else 'N/A'}\")\n",
    "        print(f\"Error Message: {e.error.message if e.error else 'N/A'}\")\n",
    "        if e.status_code == 404:\n",
    "            print(\"This is a 'Resource not found' error.\")\n",
    "            print(\"Please double-check:\")\n",
    "            print(f\"1. Endpoint: '{AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT}' is correct and the service exists.\")\n",
    "            print(f\"2. Model ID: '{MODEL_ID}' is valid for your endpoint and resource.\")\n",
    "            print(f\"3. Document URL/Path: '{DOCUMENT_URL}' (or path) is accessible.\")\n",
    "            print(\"4. API Key: Ensure it's correct and has permissions for the specified endpoint/resource.\")\n",
    "        elif e.status_code == 401 or e.status_code == 403:\n",
    "            print(\"This is an Authentication/Authorization error. Check your API Key and its permissions.\")\n",
    "        # print(f\"Full error details: {e}\") # Uncomment for more details\n",
    "    except Exception as e:\n",
    "        print(f\"\\nAn unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ตรวจสอบว่ามีการตั้งค่า Endpoint และ Key หรือไม่\n",
    "    if \"YOUR_DOCUMENT_INTELLIGENCE_ENDPOINT\" in AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT or \\\n",
    "       \"YOUR_DOCUMENT_INTELLIGENCE_KEY\" in AZURE_DOCUMENT_INTELLIGENCE_KEY:\n",
    "        print(\"ERROR: Please update the placeholders for AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT and AZURE_DOCUMENT_INTELLIGENCE_KEY in the script.\")\n",
    "    else:\n",
    "        analyze_document_from_url()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to upload 2 files in a single request...\n",
      "Prepared file: GRI 201_  Economic Performance 2016.pdf\n",
      "Prepared file: GRI 202_ Market Presence 2016.pdf\n",
      "\n",
      "Uploading 2 files now...\n",
      "Time taken to upload files: 3.8219 seconds\n",
      "Upload successful (or task accepted): {'status': 'Success', 'message': 'Successfully processed 2 files for Knowledge Graph ingestion. Question AI baseline generation has been triggered in the background.', 'original_filenames': ['GRI 201_  Economic Performance 2016.pdf', 'GRI 202_ Market Presence 2016.pdf'], 'neo4j_service_response': 'N/A'}\n",
      "Closing all file objects...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Endpoint ของคุณที่รับ List[UploadFile] และ trigger QG ทีหลัง\n",
    "url = \"http://127.0.0.1:5050/api/v1/graph/uploadfile\" # ตรวจสอบว่า URL และ port ถูกต้อง\n",
    "pdf_folder = 'pdf'  # Folder containing PDF files\n",
    "\n",
    "# Get all PDF files from the folder (หรือเลือกจำนวนที่ต้องการทดสอบ)\n",
    "pdf_file_names = [f for f in os.listdir(pdf_folder) if f.endswith('.pdf')]\n",
    "# pdf_file_names = pdf_file_names[:5] # ตัวอย่าง: ถ้าต้องการทดสอบแค่ 5 ไฟล์แรก\n",
    "\n",
    "if not pdf_file_names:\n",
    "    print(f\"No PDF files found in folder: {pdf_folder}\")\n",
    "else:\n",
    "    files_to_upload = []\n",
    "    opened_files = [] # Keep track of opened file objects to close them later\n",
    "\n",
    "    print(f\"Preparing to upload {len(pdf_file_names)} files in a single request...\")\n",
    "    for pdf_file_name in pdf_file_names:\n",
    "        file_path = os.path.join(pdf_folder, pdf_file_name)\n",
    "        try:\n",
    "            file_object = open(file_path, 'rb')\n",
    "            opened_files.append(file_object) # Add to list for later closing\n",
    "            files_to_upload.append(('files', (pdf_file_name, file_object, 'application/pdf')))\n",
    "            print(f\"Prepared file: {pdf_file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error preparing file {pdf_file_name}: {e}\")\n",
    "            # Close already opened files if error occurs during preparation\n",
    "            for f_obj in opened_files:\n",
    "                f_obj.close()\n",
    "            exit() # Exit if there's an error preparing files\n",
    "\n",
    "    if files_to_upload:\n",
    "        print(f\"\\nUploading {len(files_to_upload)} files now...\")\n",
    "        start = time.time()\n",
    "        try:\n",
    "            response = requests.post(url, files=files_to_upload)\n",
    "            end = time.time()\n",
    "            print(f\"Time taken to upload files: {end - start:.4f} seconds\")\n",
    "\n",
    "            if response.status_code == 200 or response.status_code == 202: # 202 if background task\n",
    "                print(\"Upload successful (or task accepted):\", response.json())\n",
    "            else:\n",
    "                print(\"Upload failed with status code:\", response.status_code)\n",
    "                try:\n",
    "                    print(\"Error response:\", response.json())\n",
    "                except requests.exceptions.JSONDecodeError:\n",
    "                    print(\"Error response (not JSON):\", response.text)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "        finally:\n",
    "            # Close all file objects\n",
    "            print(\"Closing all file objects...\")\n",
    "            for f_obj in opened_files:\n",
    "                f_obj.close()\n",
    "    else:\n",
    "        print(\"No files were prepared for upload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohere client initialized successfully.\n",
      "\n",
      "Attempting to get embeddings for 2 texts using model 'embed-v4.0'...\n",
      "Sample texts: ['นี่คือข้อความทดสอบภาษาไทยสำหรับการสร้าง Embedding', 'Hello from your Cohere API test script!']\n",
      "\n",
      "Successfully retrieved 2 embeddings.\n",
      "Dimension of the first embedding: 1536\n",
      "\n",
      "Cohere API test successful! Your API key and connection are working.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cohere\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# โหลด Environment Variables จากไฟล์ .env (ถ้าคุณใช้)\n",
    "load_dotenv()\n",
    "\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "if not COHERE_API_KEY:\n",
    "    print(\"Error: ไม่พบ COHERE_API_KEY ใน Environment Variables\")\n",
    "    exit()\n",
    "\n",
    "# Initialize Cohere client\n",
    "try:\n",
    "    # สำหรับ cohere SDK version ใหม่ๆ (ปกติจะใช้แบบนี้)\n",
    "    co = cohere.Client(COHERE_API_KEY)\n",
    "    # หมายเหตุ: ถ้าเป็น SDK version เก่ามากๆ อาจจะเป็น cohere.Client(api_key=COHERE_API_KEY)\n",
    "    print(\"Cohere client initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing Cohere client: {e}\")\n",
    "    exit()\n",
    "\n",
    "sample_texts = [\n",
    "    \"นี่คือข้อความทดสอบภาษาไทยสำหรับการสร้าง Embedding\",\n",
    "    \"Hello from your Cohere API test script!\"\n",
    "]\n",
    "# Model ที่คุณใช้ใน neo4j_service.py คือ 'embed-v4.0'\n",
    "# หรือลองใช้ model อื่นที่รองรับหลายภาษา เช่น 'embed-multilingual-v3.0' เพื่อทดสอบ\n",
    "# ตรวจสอบชื่อ Model ที่ถูกต้องจากเอกสารของ Cohere อีกครั้ง\n",
    "model_name = os.getenv(\"COHERE_EMBEDDING_MODEL\", \"embed-v4.0\") # ดึงมาจาก Env หรือ Hardcode\n",
    "\n",
    "print(f\"\\nAttempting to get embeddings for {len(sample_texts)} texts using model '{model_name}'...\")\n",
    "print(f\"Sample texts: {sample_texts}\")\n",
    "\n",
    "try:\n",
    "    response = co.embed(\n",
    "        texts=sample_texts,\n",
    "        model=model_name,\n",
    "        input_type=\"search_document\" # ประเภท Input สำหรับการค้นหาเอกสารทั่วไป\n",
    "                                     # อาจจะเป็น \"search_query\", \"classification\", \"clustering\" ขึ้นอยู่กับการใช้งาน\n",
    "    )\n",
    "    embeddings = response.embeddings\n",
    "    print(f\"\\nSuccessfully retrieved {len(embeddings)} embeddings.\")\n",
    "    if embeddings:\n",
    "        print(f\"Dimension of the first embedding: {len(embeddings[0])}\")\n",
    "        # print(\"First 5 dimensions of the first embedding:\", embeddings[0][:5])\n",
    "    print(\"\\nCohere API test successful! Your API key and connection are working.\")\n",
    "\n",
    "except cohere.CohereAPIError as e:\n",
    "    print(f\"\\nCohere API Error occurred:\")\n",
    "    print(f\"  Error Type: {type(e).__name__}\")\n",
    "    print(f\"  Message: {e.message if hasattr(e, 'message') else str(e)}\")\n",
    "    if hasattr(e, 'http_status'):\n",
    "        print(f\"  HTTP Status Code: {e.http_status}\")\n",
    "    if hasattr(e, 'headers'):\n",
    "        print(f\"  Headers: {e.headers}\")\n",
    "    # บางครั้ง error details อาจจะอยู่ใน e.body หรือ e.response\n",
    "    # print(f\"  Body: {e.body if hasattr(e, 'body') else 'N/A'}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nAn unexpected error occurred: {type(e).__name__} - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'content': 'ความยั่งยืนคืออะไร?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '742d536d-3c80-459c-94f6-a05362b0a87b', 'example': False}, {'content': '            Development that meets the needs of the present without compromising the ability of future generations to meet their own needs.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run--81566cec-f4d3-427f-802d-10d3c3bc881c-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 139458, 'output_tokens': 23, 'total_tokens': 139481, 'input_token_details': {'cache_read': 0}}}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Endpoint URL\n",
    "url = \"http://127.0.0.1:5050/api/v1/chat/\"\n",
    "\n",
    "# List of ESG questions\n",
    "esg_questions = [\n",
    "    \"ความยั่งยืนคืออะไร?\"\n",
    "]\n",
    "\n",
    "# Store responses\n",
    "responses = []\n",
    "\n",
    "# Posting each question to the endpoint\n",
    "for question in esg_questions:\n",
    "    payload = {\n",
    "        \"thread_id\": \"7005\",\n",
    "        \"question\": question,\n",
    "        # \"prompt\": \"No matter what is asked, always answer: 'I will get back to you'\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            responses.append(response.json())\n",
    "            print(response.json())\n",
    "        else:\n",
    "            responses.append({\"error\": f\"Failed with status code {response.status_code}\"})\n",
    "    except Exception as e:\n",
    "        print(f\"error: {e}\")\n",
    "        responses.append({\"error\": str(e)})\n",
    "\n",
    "# responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Poppler Check Script ---\n",
      "\n",
      "--- Checking pdftotext ---\n",
      "'pdftotext' IS FOUND in the system PATH.\n",
      "\n",
      "Attempting to run: pdftotext -v\n",
      "Return code: 0\n",
      "Stderr:\n",
      "pdftotext version 20.10.0\n",
      "Copyright 2005-2020 The Poppler Developers - http://poppler.freedesktop.org\n",
      "Copyright 1996-2011 Glyph & Cog, LLC\n",
      "'pdftotext' seems to be working correctly.\n",
      "\n",
      "--- Checking pdfinfo ---\n",
      "'pdfinfo' IS FOUND in the system PATH.\n",
      "\n",
      "Attempting to run: pdfinfo -v\n",
      "Return code: 0\n",
      "Stderr:\n",
      "pdfinfo version 20.10.0\n",
      "Copyright 2005-2020 The Poppler Developers - http://poppler.freedesktop.org\n",
      "Copyright 1996-2011 Glyph & Cog, LLC\n",
      "'pdfinfo' seems to be working correctly.\n",
      "\n",
      "--- Check Complete ---\n",
      "Review the output above. If commands are not found, Poppler is not in PATH or not installed correctly.\n",
      "If commands execute but show errors (other than version info in stderr), there might be an issue with the Poppler installation itself.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "def check_command_availability(command_name):\n",
    "    \"\"\"Checks if a command is available in the system PATH.\"\"\"\n",
    "    if shutil.which(command_name):\n",
    "        print(f\"'{command_name}' IS FOUND in the system PATH.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"'{command_name}' IS NOT FOUND in the system PATH.\")\n",
    "        return False\n",
    "\n",
    "def try_run_poppler_command(command_with_args):\n",
    "    \"\"\"Tries to run a Poppler command and captures output/error.\"\"\"\n",
    "    command_name = command_with_args[0]\n",
    "    if not check_command_availability(command_name):\n",
    "        print(f\"Skipping execution of '{command_name}' as it's not found in PATH.\")\n",
    "        return False\n",
    "        \n",
    "    print(f\"\\nAttempting to run: {' '.join(command_with_args)}\")\n",
    "    try:\n",
    "        # ใช้ shell=True ด้วยความระมัดระวัง และเฉพาะกับ command ที่คุณควบคุมได้\n",
    "        # สำหรับ Poppler utilities ที่ไม่มี space ในชื่อ และ -v argument มันค่อนข้างปลอดภัย\n",
    "        result = subprocess.run(command_with_args, capture_output=True, text=True, shell=True, check=False, timeout=10)\n",
    "        print(f\"Return code: {result.returncode}\")\n",
    "        if result.stdout:\n",
    "            print(f\"Stdout:\\n{result.stdout.strip()}\")\n",
    "        if result.stderr:\n",
    "            # Poppler's -v often prints to stderr, this is normal\n",
    "            print(f\"Stderr:\\n{result.stderr.strip()}\")\n",
    "        \n",
    "        if result.returncode == 0 or \"poppler version\" in result.stderr.lower() or \"pdftotext version\" in result.stderr.lower() or \"pdfinfo version\" in result.stderr.lower():\n",
    "            print(f\"'{command_name}' seems to be working correctly.\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"'{command_name}' executed but might have an issue (check output).\")\n",
    "            return False\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Command '{command_name}' not found. Make sure Poppler is installed and its bin directory is in PATH.\")\n",
    "        return False\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"Error: Command '{command_name}' timed out.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while running '{command_name}': {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Poppler Check Script ---\")\n",
    "    \n",
    "    # ตรวจสอบคำสั่งหลักๆ ของ Poppler ที่ unstructured อาจจะใช้\n",
    "    # (unstructured อาจจะไม่ได้เรียกใช้ผ่าน command line โดยตรงเสมอไป แต่เป็นการทดสอบว่า Poppler utilities พร้อมใช้งาน)\n",
    "    \n",
    "    print(\"\\n--- Checking pdftotext ---\")\n",
    "    # pdftotext -v จะแสดงเวอร์ชันไปที่ stderr\n",
    "    try_run_poppler_command([\"pdftotext\", \"-v\"])\n",
    "\n",
    "    print(\"\\n--- Checking pdfinfo ---\")\n",
    "    # pdfinfo -v จะแสดงเวอร์ชันไปที่ stderr\n",
    "    try_run_poppler_command([\"pdfinfo\", \"-v\"])\n",
    "    \n",
    "    # เพิ่มเติม: ลองกับไฟล์ PDF จริง (ถ้ามีไฟล์ PDF ง่ายๆ ไว้ทดสอบ)\n",
    "    # test_pdf_path = \"./abc/your_simple_test.pdf\" # <--- สร้างไฟล์ PDF ง่ายๆ มาวางไว้ที่นี่\n",
    "    # output_txt_path = \"./abc/test_output.txt\"\n",
    "    # if os.path.exists(test_pdf_path):\n",
    "    #     print(f\"\\n--- Trying pdftotext on a sample PDF: {test_pdf_path} ---\")\n",
    "    #     try_run_poppler_command([\"pdftotext\", test_pdf_path, output_txt_path])\n",
    "    #     if os.path.exists(output_txt_path):\n",
    "    #         print(f\"Output text file created: {output_txt_path}. Check its content.\")\n",
    "    #     else:\n",
    "    #         print(f\"Failed to create output text file from PDF.\")\n",
    "    # else:\n",
    "    #     print(f\"\\nSample PDF for pdftotext test not found at: {test_pdf_path}\")\n",
    "\n",
    "    print(\"\\n--- Check Complete ---\")\n",
    "    print(\"Review the output above. If commands are not found, Poppler is not in PATH or not installed correctly.\")\n",
    "    print(\"If commands execute but show errors (other than version info in stderr), there might be an issue with the Poppler installation itself.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing UnstructuredLoader with: ./abc/Wanwisa Sakchaiyan__CL.pdf ---\n",
      "\n",
      "Attempting to load from file_path with strategy='fast'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: pikepdf C++ to Python logger bridge initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded from path. Number of docs: 8\n",
      "First doc (first 200 chars): Wanwisa Sakchaiyan 99, Moo 9, Nong Bua Subdistrict Ban Phaeo District, Samut Sakhon, 74120 061-519-0500 | wisa.pv@gmail.com\n",
      "------------------------------\n",
      "\n",
      "Attempting to load from BytesIO with strategy='fast' (mimicking service)...\n",
      "Successfully loaded from BytesIO. Number of docs: 8\n",
      "First doc (first 200 chars): Wanwisa Sakchaiyan 99, Moo 9, Nong Bua Subdistrict Ban Phaeo District, Samut Sakhon, 74120 061-519-0500 | wisa.pv@gmail.com\n"
     ]
    }
   ],
   "source": [
    "# test_loader.py\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "import io\n",
    "import traceback\n",
    "\n",
    "pdf_file_path = './abc/Wanwisa Sakchaiyan__CL.pdf' # ตรวจสอบว่า path นี้ถูกต้องจาก root ของโปรเจกต์\n",
    "\n",
    "print(f\"--- Testing UnstructuredLoader with: {pdf_file_path} ---\")\n",
    "try:\n",
    "    print(\"\\nAttempting to load from file_path with strategy='fast'...\")\n",
    "    # ลองใช้ strategy=\"fast\" ก่อน เพราะอาจจะใช้ dependency น้อยกว่า\n",
    "    loader_from_path = UnstructuredLoader(file_path=pdf_file_path, strategy=\"fast\")\n",
    "    docs_from_path = loader_from_path.load()\n",
    "    print(f\"Successfully loaded from path. Number of docs: {len(docs_from_path)}\")\n",
    "    if docs_from_path:\n",
    "        print(f\"First doc (first 200 chars): {docs_from_path[0].page_content[:200]}\")\n",
    "except Exception as e_path:\n",
    "    print(f\"Error loading from path: {e_path}\")\n",
    "    traceback.print_exc()\n",
    "print(\"-\" * 30)\n",
    "try:\n",
    "    print(\"\\nAttempting to load from BytesIO with strategy='fast' (mimicking service)...\")\n",
    "    with open(pdf_file_path, \"rb\") as f:\n",
    "        file_content = f.read()\n",
    "    file_like_object = io.BytesIO(file_content)\n",
    "\n",
    "    loader_from_bytesio = UnstructuredLoader(file=file_like_object, metadata_filename=\"test.pdf\", strategy=\"fast\")\n",
    "    docs_from_bytesio = loader_from_bytesio.load()\n",
    "    print(f\"Successfully loaded from BytesIO. Number of docs: {len(docs_from_bytesio)}\")\n",
    "    if docs_from_bytesio:\n",
    "        print(f\"First doc (first 200 chars): {docs_from_bytesio[0].page_content[:200]}\")\n",
    "except Exception as e_bytesio:\n",
    "    print(f\"Error loading from BytesIO: {e_bytesio}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Minimal App Startup ---\n",
      "Python Executable: c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.myvenv_py312\\Scripts\\python.exe\n",
      "sys.path at minimal app startup:\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\python312.zip\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\DLLs\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\n",
      "c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.myvenv_py312\n",
      "\n",
      "c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.myvenv_py312\\Lib\\site-packages\n",
      "c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.myvenv_py312\\Lib\\site-packages\\win32\n",
      "c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.myvenv_py312\\Lib\\site-packages\\win32\\lib\n",
      "c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.myvenv_py312\\Lib\\site-packages\\Pythonwin\n",
      "Current Working Directory: c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\n",
      "PATH Environment Variable: c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.myvenv_py312\\Scripts;C:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.myvenv_py312\\Scripts;C:\\gurobi1101\\win64\\bin;C:\\Program Files (x86)\\VMware\\VMware Player\\bin\\;C:\\Program Files (x86)\\Razer Chroma SDK\\bin;C:\\Program Files\\Razer Chroma SDK\\bin;C:\\TDM-GCC-64\\bin;C:\\MinGW\\bin;C:\\Program Files (x86)\\Razer\\ChromaBroadcast\\bin;C:\\Program Files\\Razer\\ChromaBroadcast\\bin;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\110\\Tools\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\120\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\120\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\120\\DTS\\Binn\\;C:\\Program Files (x86)\\Windows Kits\\8.1\\Windows Performance Toolkit\\;C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\User\\AppData\\Local\\Programs\\MiKTeX\\miktex\\bin\\x64\\;C:\\Windows\\system32\\config\\systemprofile\\AppData\\Local\\Microsoft\\WindowsApps;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\WINDOWS\\system32\\config\\systemprofile\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files (x86)\\bin;C:\\Program Files\\MATLAB\\R2022b\\runtime\\win64;C:\\Program Files\\MATLAB\\R2022b\\bin;C:\\Program Files (x86)\\Microsoft SQL Server\\160\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\160\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\160\\DTS\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\160\\DTS\\Binn\\;C:\\Program Files\\Azure Data Studio\\bin;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Program Files\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\dotnet\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Program Files (x86)\\PIPC\\bin\\;C:\\Program Files\\Git\\cmd;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\ProgramData\\chocolatey\\bin;C:\\Program Files (x86)\\Windows Kits\\10\\Windows Performance Toolkit\\;C:\\Program Files\\nodejs\\;C:\\Users\\User\\.cargo\\bin;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\;C:\\Program Files\\MySQL\\MySQL Shell 8.0\\bin\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\;C:\\Users\\User\\anaconda3;C:\\Users\\User\\anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\User\\anaconda3\\Library\\usr\\bin;C:\\Users\\User\\anaconda3\\Library\\bin;C:\\Users\\User\\anaconda3\\Scripts;C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\User\\AppData\\Local\\Programs\\MiKTeX\\miktex\\bin\\x64\\;C:\\Program Files\\Azure Data Studio\\bin;C:\\Users\\User\\.dotnet\\tools;C:\\Users\\User\\AppData\\Local\\Programs\\Azure Data Studio\\bin;C:\\Users\\User\\AppData\\Local\\GitHubDesktop\\bin;C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts;C:\\Users\\User\\AppData\\Local\\Programs\\Ollama;C:\\Users\\User\\.cache\\lm-studio\\bin;C:\\Program Files (x86)\\poppler-24.08.0\\Library\\bin;C:\\Users\\User\\AppData\\Local\\Programs\\Tesseract-OCR;C:\\Users\\User\\.dotnet\\tools;C:\\Users\\User\\AppData\\Roaming\\npm\n",
      "--- End Minimal App Startup Info ---\n",
      "\n",
      "--- Attempting to import onnxruntime in Minimal App ---\n",
      "ONNX Runtime Version: 1.20.0\n",
      "ONNX Runtime Location: c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.myvenv_py312\\Lib\\site-packages\\onnxruntime\\__init__.py\n",
      "ONNX Available Providers: ['AzureExecutionProvider', 'CPUExecutionProvider']\n",
      "\n",
      "--- Attempting to import onnxruntime_pybind11_state in Minimal App ---\n",
      "onnxruntime_pybind11_state imported successfully in Minimal App!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 65\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinimal FastAPI app for ONNX Runtime test\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython_executable\u001b[39m\u001b[38;5;124m\"\u001b[39m: sys\u001b[38;5;241m.\u001b[39mexecutable,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpybind_import_error\u001b[39m\u001b[38;5;124m\"\u001b[39m: pybind_import_error\n\u001b[0;32m     60\u001b[0m     }\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# Run this file directly (python minimal_test.py)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Ensure your .venv is activated in the terminal you use.\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     \u001b[43muvicorn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m127.0.0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.myvenv_py312\\Lib\\site-packages\\uvicorn\\main.py:587\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[0;32m    585\u001b[0m     Multiprocess(config, target\u001b[38;5;241m=\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun, sockets\u001b[38;5;241m=\u001b[39m[sock])\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m     \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39muds \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(config\u001b[38;5;241m.\u001b[39muds):\n\u001b[0;32m    589\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(config\u001b[38;5;241m.\u001b[39muds)  \u001b[38;5;66;03m# pragma: py-win32\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.myvenv_py312\\Lib\\site-packages\\uvicorn\\server.py:61\u001b[0m, in \u001b[0;36mServer.run\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: Optional[List[socket\u001b[38;5;241m.\u001b[39msocket]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[1;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\runners.py:190\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug, loop_factory)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug, loop_factory\u001b[38;5;241m=\u001b[39mloop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "# minimal_test.py\n",
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "import sys\n",
    "import os\n",
    "import importlib.util # For checking module spec\n",
    "\n",
    "# --- Logging at startup (before ONNX import) ---\n",
    "print(\"--- Minimal App Startup ---\")\n",
    "print(f\"Python Executable: {sys.executable}\")\n",
    "print(\"sys.path at minimal app startup:\")\n",
    "for p in sys.path:\n",
    "    print(p)\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "print(f\"PATH Environment Variable: {os.environ.get('PATH')}\")\n",
    "print(\"--- End Minimal App Startup Info ---\")\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "onnx_import_error = None\n",
    "onnx_version = None\n",
    "onnx_file_location = None\n",
    "onnx_providers = None\n",
    "pybind_import_error = None\n",
    "\n",
    "try:\n",
    "    print(\"\\n--- Attempting to import onnxruntime in Minimal App ---\")\n",
    "    import onnxruntime\n",
    "    onnx_version = onnxruntime.__version__\n",
    "    onnx_file_location = onnxruntime.__file__\n",
    "    onnx_providers = onnxruntime.get_available_providers()\n",
    "    print(f\"ONNX Runtime Version: {onnx_version}\")\n",
    "    print(f\"ONNX Runtime Location: {onnx_file_location}\")\n",
    "    print(f\"ONNX Available Providers: {onnx_providers}\")\n",
    "\n",
    "    print(\"\\n--- Attempting to import onnxruntime_pybind11_state in Minimal App ---\")\n",
    "    from onnxruntime.capi import onnxruntime_pybind11_state\n",
    "    print(\"onnxruntime_pybind11_state imported successfully in Minimal App!\")\n",
    "\n",
    "except ImportError as e_imp:\n",
    "    print(f\"ImportError in Minimal App: {e_imp}\")\n",
    "    onnx_import_error = str(e_imp)\n",
    "    if \"onnxruntime_pybind11_state\" in str(e_imp):\n",
    "        pybind_import_error = str(e_imp)\n",
    "except Exception as e_exc:\n",
    "    print(f\"Unexpected error during import in Minimal App: {e_exc}\")\n",
    "    onnx_import_error = str(e_exc)\n",
    "\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\n",
    "        \"message\": \"Minimal FastAPI app for ONNX Runtime test\",\n",
    "        \"python_executable\": sys.executable,\n",
    "        \"onnx_version\": onnx_version,\n",
    "        \"onnx_location\": onnx_file_location,\n",
    "        \"onnx_providers\": onnx_providers,\n",
    "        \"onnx_import_error\": onnx_import_error,\n",
    "        \"pybind_import_error\": pybind_import_error\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run this file directly (python minimal_test.py)\n",
    "    # Ensure your .venv is activated in the terminal you use.\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "# คุณสามารถตรวจสอบได้ด้วยว่า PyTorch สามารถใช้ CUDA ได้หรือไม่ (ถ้าคุณต้องการ GPU support)\n",
    "# print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# print(f\"CUDA version: {torch.version.cuda}\") # ถ้า CUDA available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- sys.path ---\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\python312.zip\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\DLLs\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\n",
      "c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.venv\n",
      "\n",
      "c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.venv\\Lib\\site-packages\n",
      "c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.venv\\Lib\\site-packages\\win32\n",
      "c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.venv\\Lib\\site-packages\\win32\\lib\n",
      "c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.venv\\Lib\\site-packages\\Pythonwin\n",
      "--- end sys.path ---\n",
      "\n",
      "--- Attempting to import onnxruntime ---\n",
      "ONNX Runtime imported successfully!\n",
      "Version: 1.22.0\n",
      " Tämä on onnxruntime-kirjaston sijainti: c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.venv\\Lib\\site-packages\\onnxruntime\\__init__.py\n",
      "Käytettävissä olevat suorituskyvyn tarjoajat: ['AzureExecutionProvider', 'CPUExecutionProvider']\n",
      "\n",
      "--- Attempting to import onnxruntime_pybind11_state ---\n",
      "onnxruntime_pybind11_state imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"--- sys.path ---\")\n",
    "for p in sys.path:\n",
    "    print(p)\n",
    "print(\"--- end sys.path ---\")\n",
    "\n",
    "print(\"\\n--- Attempting to import onnxruntime ---\")\n",
    "try:\n",
    "    import onnxruntime\n",
    "    print(\"ONNX Runtime imported successfully!\")\n",
    "    print(f\"Version: {onnxruntime.__version__}\")\n",
    "    print(f\" Tämä on onnxruntime-kirjaston sijainti: {onnxruntime.__file__}\") # Location of onnxruntime\n",
    "    print(f\"Käytettävissä olevat suorituskyvyn tarjoajat: {onnxruntime.get_available_providers()}\") # Available execution providers\n",
    "except ImportError as e:\n",
    "    print(f\"ImportError during onnxruntime import: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during onnxruntime import: {e}\")\n",
    "\n",
    "print(\"\\n--- Attempting to import onnxruntime_pybind11_state ---\")\n",
    "try:\n",
    "    from onnxruntime.capi import onnxruntime_pybind11_state\n",
    "    print(\"onnxruntime_pybind11_state imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"ImportError during onnxruntime_pybind11_state import: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while importing onnxruntime_pybind11_state: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Uvicorn Application PATH Environment Variable ---\n",
      "c:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.venv\\Scripts;C:\\Users\\User\\Downloads\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\ESG-LLM-finetune-and-Graph-RAG-main\\.venv\\Scripts;C:\\gurobi1101\\win64\\bin;C:\\Program Files (x86)\\VMware\\VMware Player\\bin\\;C:\\Program Files (x86)\\Razer Chroma SDK\\bin;C:\\Program Files\\Razer Chroma SDK\\bin;C:\\TDM-GCC-64\\bin;C:\\MinGW\\bin;C:\\Program Files (x86)\\Razer\\ChromaBroadcast\\bin;C:\\Program Files\\Razer\\ChromaBroadcast\\bin;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Windows\\System32\\OpenSSH\\;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\110\\Tools\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\120\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\120\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\120\\DTS\\Binn\\;C:\\Program Files (x86)\\Windows Kits\\8.1\\Windows Performance Toolkit\\;C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\User\\AppData\\Local\\Programs\\MiKTeX\\miktex\\bin\\x64\\;C:\\Windows\\system32\\config\\systemprofile\\AppData\\Local\\Microsoft\\WindowsApps;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\WINDOWS\\system32\\config\\systemprofile\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files (x86)\\bin;C:\\Program Files\\MATLAB\\R2022b\\runtime\\win64;C:\\Program Files\\MATLAB\\R2022b\\bin;C:\\Program Files (x86)\\Microsoft SQL Server\\160\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\160\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\Client SDK\\ODBC\\170\\Tools\\Binn\\;C:\\Program Files\\Microsoft SQL Server\\160\\DTS\\Binn\\;C:\\Program Files (x86)\\Microsoft SQL Server\\160\\DTS\\Binn\\;C:\\Program Files\\Azure Data Studio\\bin;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\;C:\\WINDOWS\\System32\\OpenSSH\\;C:\\Program Files\\Microsoft SQL Server\\150\\Tools\\Binn\\;C:\\Program Files\\dotnet\\;C:\\Program Files\\Docker\\Docker\\resources\\bin;C:\\Program Files (x86)\\PIPC\\bin\\;C:\\Program Files\\Git\\cmd;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\ProgramData\\chocolatey\\bin;C:\\Program Files (x86)\\Windows Kits\\10\\Windows Performance Toolkit\\;C:\\Program Files\\nodejs\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Scripts\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\;C:\\Program Files\\MySQL\\MySQL Shell 8.0\\bin\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\Scripts\\;C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\;C:\\Users\\User\\anaconda3;C:\\Users\\User\\anaconda3\\Library\\mingw-w64\\bin;C:\\Users\\User\\anaconda3\\Library\\usr\\bin;C:\\Users\\User\\anaconda3\\Library\\bin;C:\\Users\\User\\anaconda3\\Scripts;C:\\Users\\User\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\User\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\User\\AppData\\Local\\Programs\\MiKTeX\\miktex\\bin\\x64\\;C:\\Program Files\\Azure Data Studio\\bin;C:\\Users\\User\\.dotnet\\tools;C:\\Users\\User\\AppData\\Local\\Programs\\Azure Data Studio\\bin;C:\\Users\\User\\AppData\\Local\\GitHubDesktop\\bin;C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\Scripts;C:\\Users\\User\\AppData\\Local\\Programs\\Ollama;C:\\Users\\User\\.cache\\lm-studio\\bin;C:\\Program Files (x86)\\poppler-24.08.0\\Library\\bin;C:\\Users\\User\\AppData\\Local\\Programs\\Tesseract-OCR;C:\\Users\\User\\.dotnet\\tools;C:\\Users\\User\\AppData\\Roaming\\npm\n",
      "--- End PATH ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print(\"--- Uvicorn Application PATH Environment Variable ---\")\n",
    "print(os.environ.get('PATH'))\n",
    "print(\"--- End PATH ---\")\n",
    "# ... (โค้ด logging sys.path และ onnxruntime import ที่เคยแนะนำ) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "url = \"http://127.0.0.1:8000/api/v1/graph/uploadfile\"\n",
    "\n",
    "files = [\n",
    "    ('files', ('DocA.pdf', open('pdf/0a114341-0e93-4a94-8327-e9254026920b.pdf', 'rb'), 'application/pdf')),\n",
    "    ('files', ('789_03 Property_SET ESG Metrics full (1).pdf', open('./pdf/789_03 Property_SET ESG Metrics full (1).pdf', 'rb'), 'application/pdf')),\n",
    "    ('files', ('T-VER-P-METH-13-08 Good practices in Paddy Rice Version 01_250967.pdf', open('./pdf/T-VER-P-METH-13-08 Good practices in Paddy Rice Version 01_250967.pdf', 'rb'), 'application/pdf')),\n",
    "    ('files', ('T-VER-P-METH-13-06 Version 01_EN.pdf', open('./pdf/T-VER-P-METH-13-06 Version 01_EN.pdf', 'rb'), 'application/pdf')),\n",
    "]\n",
    "print(\"Uploading files...\")\n",
    "start = time.time()\n",
    "response = requests.post(url, files=files)\n",
    "end = time.time()\n",
    "print(\"Time taken to upload files: \", end-start)\n",
    "print(response.json())  # This will print the JSON response from the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n"
     ]
    }
   ],
   "source": [
    "import magic\n",
    "print(magic.from_buffer('hello world'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for installation to finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2128126973.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    importing onnxruntime_pybind11_state\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "importing onnxruntime_pybind11_state\n",
    "print(onnxruntime.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to upload 2 files in a single request...\n",
      "Prepared file: 386_05 Industrials_SET ESG Metrics full_compressed.pdf\n",
      "Prepared file: GRI 1_ Foundation 2021.pdf\n",
      "\n",
      "Uploading 2 files now...\n",
      "Time taken to upload files: 0.0100 seconds\n",
      "Upload failed with status code: 404\n",
      "Error response: {'detail': 'Not Found'}\n",
      "Closing all file objects...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Endpoint ของคุณที่รับ List[UploadFile] และ trigger QG ทีหลัง\n",
    "url = \"http://127.0.0.1:5050/api/v1/graph/uploadfile\" # ตรวจสอบว่า URL และ port ถูกต้อง\n",
    "pdf_folder = 'pdf'  # Folder containing PDF files\n",
    "\n",
    "# Get all PDF files from the folder (หรือเลือกจำนวนที่ต้องการทดสอบ)\n",
    "pdf_file_names = [f for f in os.listdir(pdf_folder) if f.endswith('.pdf')]\n",
    "# pdf_file_names = pdf_file_names[:5] # ตัวอย่าง: ถ้าต้องการทดสอบแค่ 5 ไฟล์แรก\n",
    "\n",
    "if not pdf_file_names:\n",
    "    print(f\"No PDF files found in folder: {pdf_folder}\")\n",
    "else:\n",
    "    files_to_upload = []\n",
    "    opened_files = [] # Keep track of opened file objects to close them later\n",
    "\n",
    "    print(f\"Preparing to upload {len(pdf_file_names)} files in a single request...\")\n",
    "    for pdf_file_name in pdf_file_names:\n",
    "        file_path = os.path.join(pdf_folder, pdf_file_name)\n",
    "        try:\n",
    "            file_object = open(file_path, 'rb')\n",
    "            opened_files.append(file_object) # Add to list for later closing\n",
    "            files_to_upload.append(('files', (pdf_file_name, file_object, 'application/pdf')))\n",
    "            print(f\"Prepared file: {pdf_file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error preparing file {pdf_file_name}: {e}\")\n",
    "            # Close already opened files if error occurs during preparation\n",
    "            for f_obj in opened_files:\n",
    "                f_obj.close()\n",
    "            exit() # Exit if there's an error preparing files\n",
    "\n",
    "    if files_to_upload:\n",
    "        print(f\"\\nUploading {len(files_to_upload)} files now...\")\n",
    "        start = time.time()\n",
    "        try:\n",
    "            response = requests.post(url, files=files_to_upload)\n",
    "            end = time.time()\n",
    "            print(f\"Time taken to upload files: {end - start:.4f} seconds\")\n",
    "\n",
    "            if response.status_code == 200 or response.status_code == 202: # 202 if background task\n",
    "                print(\"Upload successful (or task accepted):\", response.json())\n",
    "            else:\n",
    "                print(\"Upload failed with status code:\", response.status_code)\n",
    "                try:\n",
    "                    print(\"Error response:\", response.json())\n",
    "                except requests.exceptions.JSONDecodeError:\n",
    "                    print(\"Error response (not JSON):\", response.text)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Request failed: {e}\")\n",
    "        finally:\n",
    "            # Close all file objects\n",
    "            print(\"Closing all file objects...\")\n",
    "            for f_obj in opened_files:\n",
    "                f_obj.close()\n",
    "    else:\n",
    "        print(\"No files were prepared for upload.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python312.zip', 'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\DLLs', 'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib', 'C:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312', 'c:\\\\Users\\\\User\\\\Downloads\\\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\\\ESG-LLM-finetune-and-Graph-RAG-main\\\\.venv', '', 'c:\\\\Users\\\\User\\\\Downloads\\\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\\\ESG-LLM-finetune-and-Graph-RAG-main\\\\.venv\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\User\\\\Downloads\\\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\\\ESG-LLM-finetune-and-Graph-RAG-main\\\\.venv\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\User\\\\Downloads\\\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\\\ESG-LLM-finetune-and-Graph-RAG-main\\\\.venv\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\User\\\\Downloads\\\\ESG-LLM-finetune-and-Graph-RAG-mainesg (5)\\\\ESG-LLM-finetune-and-Graph-RAG-main\\\\.venv\\\\Lib\\\\site-packages\\\\Pythonwin']\n",
      "ONNX Runtime imported successfully!\n",
      "Version: 1.22.0\n",
      "onnxruntime_pybind11_state imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path) # ดูว่า Python มองหา module จากที่ไหนบ้าง\n",
    "try:\n",
    "    import onnxruntime\n",
    "    print(\"ONNX Runtime imported successfully!\")\n",
    "    print(f\"Version: {onnxruntime.__version__}\")\n",
    "    # ลองเรียกฟังก์ชันพื้นฐาน (ถ้ามี)\n",
    "    # print(onnxruntime.get_available_providers())\n",
    "except ImportError as e:\n",
    "    print(f\"ImportError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during import: {e}\")\n",
    "\n",
    "# ลอง import ส่วนที่ error โดยตรง (อาจจะไม่ใช่ public API แต่เพื่อทดสอบ)\n",
    "try:\n",
    "    from onnxruntime.capi import onnxruntime_pybind11_state\n",
    "    print(\"onnxruntime_pybind11_state imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"Failed to import onnxruntime_pybind11_state: {e}\") # นี่คือ error ที่คุณเจอ\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while importing onnxruntime_pybind11_state: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think it work now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'content': 'How does your organization measure and manage its carbon footprint?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': 'aba9bc67-efb7-4764-a46d-ced0541c79ee', 'example': False}, {'content': 'The organization uses the FTSE ESG Ratings Model, which assesses companies based on three dimensions (Environment, Social, and Governance), 14 themes, and 300+ indicators, focusing on data transparency, materiality, outcome, and performance against targets.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-a5c4a69f-0c24-4845-8deb-7fd34edee6ba-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 18294, 'output_tokens': 52, 'total_tokens': 18346, 'input_token_details': {'cache_read': 0}}}, {'content': 'What are your company’s long-term environmental goals?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '2d25ba68-84f5-4308-ada2-79bf5ad2f2f1', 'example': False}, {'content': 'The Stock Exchange of Thailand will accelerate working closely with all sectors to enable all parties to adapt and be ready to upgrade the assessment to international standards, which will help develop the potential of the Thai capital market to be more outstanding in terms of sustainability and attractive to investors.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-d884431a-f40b-45aa-98e8-a55f01b99d33-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 15984, 'output_tokens': 54, 'total_tokens': 16038, 'input_token_details': {'cache_read': 0}}}, {'content': 'How does your organization measure and manage its carbon footprint?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '0f77ed01-5c6f-443e-a93f-fc5300492e4f', 'example': False}, {'content': 'The organization uses the FTSE ESG Ratings Model, which assesses companies based on three dimensions (Environment, Social, and Governance), 14 themes, and 300+ indicators, focusing on data transparency, materiality, outcome, and performance against targets.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-8dee4086-1cd8-414a-836a-23a15510e730-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 18422, 'output_tokens': 52, 'total_tokens': 18474, 'input_token_details': {'cache_read': 0}}}, {'content': 'What policies does your company have to reduce waste production?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '11592950-3cc8-4728-8973-eed3251933fa', 'example': False}, {'content': \"I don't know the answer.\", 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-dd5901de-6ac4-4a46-bc34-0d18e4a3b5eb-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 18587, 'output_tokens': 9, 'total_tokens': 18596, 'input_token_details': {'cache_read': 0}}}, {'content': 'How does your organization measure and manage its carbon footprint?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '28412e6c-3893-4b03-946e-3d18e4d07f34', 'example': False}, {'content': 'The organization is certified with the Carbon Footprint Label by the Thailand Greenhouse Gas Management Organization.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-7e2d5ada-79a8-4324-88b8-a9ed1d5b7a0a-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 45504, 'output_tokens': 17, 'total_tokens': 45521, 'input_token_details': {'cache_read': 0}}}, {'content': 'What are your company’s long-term environmental goals?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '08bb8508-faca-4cf3-a81c-4fc90164d016', 'example': False}, {'content': 'The long-term environmental goals include setting a target to reduce net greenhouse gas emissions to zero (Net Zero) by 2030, converting fuel in production to 100% renewable energy, and developing a business model that focuses on the Circular Economy.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-a77237fe-fb46-4694-9bf8-f73be391a121-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 58360, 'output_tokens': 54, 'total_tokens': 58414, 'input_token_details': {'cache_read': 0}}}, {'content': 'How does your organization measure and manage its carbon footprint?', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '2d982d12-34c7-4d26-8cef-f0f836bf9493', 'example': False}, {'content': 'The organization is certified for the Chain of Custody (CoC) according to Forest Stewardship Council (FSC) and Programme for the Endorsement of Forest Certification (PEFC) standards and has a Climate Change Mitigation and Adaptation Plan. This plan includes short-term measures such as installing rainwater harvesting and wastewater treatment systems, medium-term goals like reducing greenhouse gas emissions by 25% by 2022, and long-term objectives such as achieving net-zero emissions by 2030 and converting to 100% renewable energy.', 'additional_kwargs': {}, 'response_metadata': {'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, 'type': 'ai', 'name': None, 'id': 'run-a9f00896-fffa-4d5a-a7a4-fd632dabe4ef-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 45598, 'output_tokens': 112, 'total_tokens': 45710, 'input_token_details': {'cache_read': 0}}}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Endpoint URL\n",
    "url = \"http://127.0.0.1:8000/api/v1/chat/\"\n",
    "\n",
    "# List of ESG questions\n",
    "esg_questions = [\n",
    "    \"How does your organization measure and manage its carbon footprint?\",\n",
    "    # \"What are your company’s long-term environmental goals?\",\n",
    "    # \"How do you ensure sustainable sourcing for raw materials?\",\n",
    "    # \"What policies does your company have to reduce waste production?\",\n",
    "    # \"How are you minimizing water usage across your operations?\",\n",
    "    # \"What diversity and inclusion initiatives are currently in place?\",\n",
    "    # \"How does the organization support community development and social causes?\",\n",
    "    # \"What steps does your company take to ensure fair labor practices?\",\n",
    "    # \"How do you engage with employees to maintain high workplace satisfaction?\",\n",
    "    # \"What are your policies on health and safety for employees?\",\n",
    "    # \"What practices does your company have to maintain transparent corporate governance?\",\n",
    "    # \"How does the board ensure compliance with ethical standards?\",\n",
    "    # \"What is your policy on executive compensation?\",\n",
    "    # \"How are ESG risks integrated into your overall risk management framework?\",\n",
    "    # \"How do you ensure accountability at all levels within the company?\",\n",
    "    # \"How many organizer in this project?\",\n",
    "    # \"What does this data about?\",\n",
    "    # \"How many node are there?\",\n",
    "    # \"Summary all this in 100 word\",\n",
    "    # \"Pick one file name for me\"\n",
    "]\n",
    "\n",
    "# Store responses\n",
    "responses = []\n",
    "\n",
    "# Posting each question to the endpoint\n",
    "for question in esg_questions:\n",
    "    payload = {\n",
    "        \"thread_id\": \"99999\",\n",
    "        \"question\": question,\n",
    "        # \"prompt\": \"No matter what is asked, always answer: 'I will get back to you'\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        if response.status_code == 200:\n",
    "            responses.append(response.json())\n",
    "            print(response.json())\n",
    "        else:\n",
    "            responses.append({\"error\": f\"Failed with status code {response.status_code}\"})\n",
    "    except Exception as e:\n",
    "        print(f\"error: {e}\")\n",
    "        responses.append({\"error\": str(e)})\n",
    "\n",
    "# responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "url = \"http://127.0.0.1:8000/api/v1/chat/\"\n",
    "\n",
    "esg_questions = [\n",
    "    \"How does your organization measure and manage its carbon footprint?\",\n",
    "    \"What are your company’s long-term environmental goals?\",\n",
    "    \"How do you ensure sustainable sourcing for raw materials?\",\n",
    "    \"What policies does your company have to reduce waste production?\",\n",
    "    \"How are you minimizing water usage across your operations?\",\n",
    "    # \"What diversity and inclusion initiatives are currently in place?\",\n",
    "    # \"How does the organization support community development and social causes?\",\n",
    "    # \"What steps does your company take to ensure fair labor practices?\",\n",
    "    # \"How do you engage with employees to maintain high workplace satisfaction?\",\n",
    "    # \"What are your policies on health and safety for employees?\",\n",
    "    # \"What practices does your company have to maintain transparent corporate governance?\",\n",
    "    # \"How does the board ensure compliance with ethical standards?\",\n",
    "    # \"What is your policy on executive compensation?\",\n",
    "    # \"How are ESG risks integrated into your overall risk management framework?\",\n",
    "    # \"How do you ensure accountability at all levels within the company?\",\n",
    "    # \"How many organizer in this project?\",\n",
    "    # \"What does this data about?\",\n",
    "    # \"How many node are there?\",\n",
    "    # \"Summary all this in 100 word\",\n",
    "    # \"Pick one file name for me\"\n",
    "]\n",
    "\n",
    "def post_question(q):\n",
    "    payload = {\n",
    "        \"thread_id\": \"99999\",\n",
    "        \"question\": q,\n",
    "        # \"prompt\": \"No matter what is asked, always answer: 'I will get back to you'\"\n",
    "    }\n",
    "    try:\n",
    "        resp = requests.post(url, json=payload)\n",
    "        if resp.status_code == 200:\n",
    "            return resp.json()\n",
    "        else:\n",
    "            return {\"error\": f\"Failed with status code {resp.status_code}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# Clear or reuse the 'responses' variable; here we reinitialize it\n",
    "responses = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    future_to_question = {executor.submit(post_question, q): q for q in esg_questions}\n",
    "    for future in concurrent.futures.as_completed(future_to_question):\n",
    "        result = future.result()\n",
    "        responses.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneQuestion = 10 sec\n",
    "# fiveQuestion = 37.8 sec\n",
    "# tenQuestion = 63.8 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The organization uses the FTSE ESG Ratings Model, which assesses companies based on three dimensions (Environment, Social, and Governance), 14 themes, and 300+ indicators, focusing on data transparency, materiality, outcome, and performance against targets.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[0]['messages'][-1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"content\": \"How does your organization measure and manage its carbon footprint?\",\n",
    "            \"additional_kwargs\": {},\n",
    "            \"response_metadata\": {},\n",
    "            \"type\": \"human\",\n",
    "            \"name\": None,\n",
    "            \"id\": \"7afe5575-4c0d-4afd-a6d1-e2bd5cad26b5\",\n",
    "            \"example\": False\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"The organization uses the FTSE ESG Ratings Model, which considers three dimensions (Environment, Social, and Governance), 14 themes, and 300+ indicators to score each company's ESG operations and performance. The assessment focuses on data transparency, materiality, outcome, and performance, and is aligned with global standards.\",\n",
    "            \"additional_kwargs\": {},\n",
    "            \"response_metadata\": {\n",
    "                \"prompt_feedback\": {\n",
    "                    \"block_reason\": 0,\n",
    "                    \"safety_ratings\": []\n",
    "                },\n",
    "                \"finish_reason\": \"STOP\",\n",
    "                \"safety_ratings\": []\n",
    "            },\n",
    "            \"type\": \"ai\",\n",
    "            \"name\": None,\n",
    "            \"id\": \"run-772d555c-cae0-46d7-a194-42f3797c229c-0\",\n",
    "            \"example\": False,\n",
    "            \"tool_calls\": [],\n",
    "            \"invalid_tool_calls\": [],\n",
    "            \"usage_metadata\": {\n",
    "                \"input_tokens\": 18294,\n",
    "                \"output_tokens\": 66,\n",
    "                \"total_tokens\": 18360,\n",
    "                \"input_token_details\": {\n",
    "                    \"cache_read\": 0\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"How does your organization measure and manage its carbon footprint?\",\n",
    "            \"additional_kwargs\": {},\n",
    "            \"response_metadata\": {},\n",
    "            \"type\": \"human\",\n",
    "            \"name\": None,\n",
    "            \"id\": \"91f8762b-7151-40d4-b83c-0891ac100cd0\",\n",
    "            \"example\": False\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"The organization uses the FTSE ESG Ratings Model, which considers three dimensions (Environment, Social, and Governance), 14 themes, and 300+ indicators to score each company's ESG operations and performance, focusing on data transparency, materiality, outcome, and performance, and aligned with global standards.\",\n",
    "            \"additional_kwargs\": {},\n",
    "            \"response_metadata\": {\n",
    "                \"prompt_feedback\": {\n",
    "                    \"block_reason\": 0,\n",
    "                    \"safety_ratings\": []\n",
    "                },\n",
    "                \"finish_reason\": \"STOP\",\n",
    "                \"safety_ratings\": []\n",
    "            },\n",
    "            \"type\": \"ai\",\n",
    "            \"name\": None,\n",
    "            \"id\": \"run-0aef109b-6479-492a-89cb-8748447b89ce-0\",\n",
    "            \"example\": False,\n",
    "            \"tool_calls\": [],\n",
    "            \"invalid_tool_calls\": [],\n",
    "            \"usage_metadata\": {\n",
    "                \"input_tokens\": 18371,\n",
    "                \"output_tokens\": 64,\n",
    "                \"total_tokens\": 18435,\n",
    "                \"input_token_details\": {\n",
    "                    \"cache_read\": 0\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'detail': 'Messages for thread_id 99999 successfully deleted.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "delete_thread = \"99999\"\n",
    "\n",
    "# Endpoint URL\n",
    "url = f\"http://127.0.0.1:8000/api/v1/chat/{delete_thread}\"\n",
    "\n",
    "try:\n",
    "    response = requests.delete(url)\n",
    "    if response.status_code == 200:\n",
    "        print(response.json())\n",
    "    else:\n",
    "        print(f\"Failed with status code {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"error: {e}\")\n",
    "    responses.append({\"error\": str(e)})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myvenv_py312 (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
